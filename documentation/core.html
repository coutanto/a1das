<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>a1das.core API documentation</title>
<meta name="description" content="Generic IO functions to open/read/plot
febus/reducted/socket das files" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>a1das.core</code></h1>
</header>
<section id="section-intro">
<p>Generic IO functions to open/read/plot
febus/reducted/socket das files</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#  Module to perform basic IO operations on A1 DAS data from file and socket stream,
#
# O. Coutant, ISTerre, UGA, 2020
#
# Content:
#   Definition of classes A1File, A1Section,...
#   (see details of content below)
#
# class A1File:
# ------------
#    members = file_header   (class _A1FileHeader)
#              socket_header (class _A1SocketHeader)
#              data_header   (dict)
#
#    methods:
#                __init__()
#                __str__() (print(A1File)
#
#               read()                    : read data with various selection options and return an A1Section instance
#               set_otime_from_filename() : set origin time from filename
#               close()                   : close file/socket stream
#    functions:
#               open()                    : open and return a file/socket description
#               tcp_address()             : format a socket address for ZMQ given IP address and port
#
# class A1Section:
# ---------------
#
#    members =  data_header   (dict)
#               data          (numpy 2D ndarray)
#    methods:
#               set_otime_from_filename() : set origin time from filename
#               obspy_stream()            : convert to obspy
#               time()                    : return time vector
#               dist()                    : return distance vector
#               plot()                    : simple plot vector
#               rplot()                   : simple plot ratser

#
# Content
#
# class _A1SocketHeader
# class _A1FileHeader
# &#34;class&#34; _A1DataHeader (actually not a class but just a dictionnary)
#
# class A1File
# class A1Section
# function open()
#
__version__ = &#34;a1das Version 2.0.0&#34;

__doc__=&#34;Generic IO functions to open/read/plot  febus/reducted/socket das files&#34;
#
# ================================= _A1SocketHeader ================================
#
class _A1SocketHeader:
    def __init__(self,  socket=None,  socket_name=None, time_stamp=0., running_time=0.):
        self.socket = socket
        self.socketname = socket_name
        self.time_stamp = time_stamp
        self.running_time = running_time

    def __str__(self):
        from io import StringIO
        s = StringIO()
        s.write(&#39;\n&lt;_A1SocketHeader&gt;:&#39;)
        s.write(&#39;\n-----------&#39;)
        s.write(&#39;\nsocketname: &#39;+self.socketname)
        s.write(&#39;\nrunning_time:&#39;+str(self.running_time))
        return s.getvalue()

#
# ================================= _A1FileHeader ================================
#
class _A1FileHeader:

    def __init__(self,  freq_res, block_info, srate_node, chan_node, type, fd, filename):
        self.freq_res = freq_res    # frequency at which data are written on file
        self.srate_node = srate_node # hdf5 handle
        self.chan_node = chan_node   # hdf5 handle
        self.block_info = block_info # block info dict
        self.type = type                # &#39;febus&#39; or &#39;reducted&#39;
        self.fd = fd                    # file descriptor
        self.filename = filename        # as said

    def __str__(self):
        from io import StringIO
        s = StringIO()
        s.write(&#39;\n&lt;_A1FileHeader&gt;:&#39;)
        s.write(&#39;\n-----------------&#39;)
        s.write(&#39;\nfile type: &#39;+self.type)
        s.write(&#39;\nfilename: &#39; + self.filename)
        if self.block_info is not None:
            for key, value in self.block_info.items():
                s.write(&#39;\n&#39;+key+&#39;=&#39;+str(value))
        return s.getvalue()


#
# ================================= class _A1DataHeader ================================
#
class _A1DataHeader:
    def __init__(self, gauge_length=None, sampling_res=None, prf=None, derivation_time=None,
                    data_type=None, data_axis=None, pos=None, dt=None, ntime=None, otime=None, dx=None, nspace=None,
                    ospace=None,dist=None, time=None, **kwargs):
        &#34;&#34;&#34;
        fill the _A1DataHeader._header{} dictionnary with values passed as args

        gauge_length h   # gauge length
        sampling_res     # original spatial resolution
        derivation_time  # time step for time derivation
        prf              # pulse rate frequency
        pos              # 3D array of geographical coordinates
        data_type        # &#39;raw&#39;, &#39;strain&#39;, &#39;strain-rate&#39;
        data_axis        # &#39;time_x_space&#39; or &#39;space_x_time&#39;
        dt               # time step
        ntime            # number of time samples
        time             # time vector
        otime            # origin time
        dx               # space step along fiber
        dist             # distance vector along fiber
        nspace           # number of space samples
        ospace           # origin position along fiber

        Note: why data_header is not a simple dictionnary?
        because we want to keep a predefined set of metadata, even if not defined (or None),
        and do this via the __init__() method that documents it
        &#34;&#34;&#34;
        self._header = {
            &#39;gauge_length&#39;: gauge_length,  # gauge length
            &#39;sampling_res&#39;: sampling_res,  # original spatial resolution
            &#39;derivation_time&#39;: derivation_time,  # time step for time derivation
            &#39;prf&#39;: prf,  # pulse rate frequency
            &#39;pos&#39;: pos,  # 3D array of geographical coordinates
            &#39;data_type&#39;: data_type,  # &#39;raw&#39;, &#39;strain&#39;, &#39;strain-rate&#39;
            &#39;data_axis&#39;: data_axis,  # &#39;time_x_space&#39; or &#39;space_x_time&#39;
            &#39;dt&#39;: dt,  # time step
            &#39;ntime&#39;: ntime,  # number of time samples
            &#39;otime&#39;: otime,  # origin time in Posix format
            &#39;dx&#39;: dx,  # space step along fiber
            &#39;nspace&#39;: nspace,  # number of space samples
            &#39;ospace&#39;: ospace,  # origin position along fiber
            &#39;time&#39;: time,
            &#39;dist&#39;: dist
        }
        for key, value in kwargs.items():
            self._header[key] = value

    def __getitem__(self, item):
        &#34;&#34;&#34;
        overload [] operator for the _A1DataHeader class
        &#34;&#34;&#34;
        try:
            return self._header[item]
        except:
            return None

    def copy(self):
        &#34;&#34;&#34;
        # Description
        Create and copy a data_header with a &#39;real&#39; copy of the dictionnary
        #Description return:
        a new instance of _A1DataHeader filled with the value of the calling instance
        &#34;&#34;&#34;
        dhdout = _A1DataHeader()
        dhdout._header = self._header.copy()
        return dhdout

    def __str__(self):

        from io import StringIO
        from numpy import ndarray
        from datetime import datetime, timezone

        unit = {&#39;gauge_length&#39;: &#39; [m]&#39;,
                &#39;sampling_res&#39;: &#39; [cm]&#39;,
                &#39;derivation_time&#39;: &#39; [msec]&#39;,
                &#39;dt&#39;: &#39; [sec]&#39;,
                &#39;dx&#39;: &#39; [m]&#39;
                }

        s = StringIO()
        s.write(&#39;\n&lt;_A1DataHeader&gt;:&#39;)
        s.write(&#39;\n-----------------&#39;)
        for key, value in self._header.items():
            if value is None:
                continue
            if isinstance(value, ndarray):
                continue
            try:
                su = unit[key]
                s.write(&#39;\n&#39; + str(key) + &#39;= &#39; + str(value) + su)
            except:
                s.write(&#39;\n&#39; + str(key) + &#39;= &#39; + str(value))

            if key == &#39;otime&#39;:
                s.write(&#39;  &lt;=&gt; date =&#39; + str(datetime.fromtimestamp(value, tz=timezone.utc)))

        if self._header[&#39;time&#39;] is not None:
            time = self._header[&#39;time&#39;]
            s.write(&#39;\n\nTotal time duration :&#39; + str(time[-1] - time[0]) + &#39; [sec]&#39;)
        if self._header[&#39;dist&#39;] is not None:
            dist = self._header[&#39;dist&#39;]
            s.write(&#39;\nTotal distance :&#39; + str(dist[-1] - dist[0]) + &#39; [m]&#39;)

        return s.getvalue()

    def __repr__(self):
        return self.__str__()

    def set_item(self, **kwargs):
        for key, value in kwargs.items():
            self._header[key]=value

    def keys(self):
        return self._header.keys()
    #
    # ====================================   INDEX()  =======================================
    #
    def index(self, drange=None, trange=None):
        &#34;&#34;&#34;
        ## Description
        Return the index or list of indices that correspond(s) to the list of distance(resp. time) range
        in the &#39;distance&#39; vector (resp. time vector)

        ## Input
        !!!!! Only one of trange or drange can be given

        drange = [unique_dist]; [dist_min, dist_max]; [d1, d2, ... dN]  (default = None)

        trange = [unique_time]; [time_min, time_max]; [t1, t2, ... tN]  (default = None)

        ## Return
        A list of indices that matches the given range in the A1Section.data_header[&#39;dist&#39;] or
        A1Section.data_header[&#39;time&#39;] vectors

        ## Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f=open(&#39;filename&#39;)
        &gt;&gt;&gt; a=f.read()
        &gt;&gt;&gt; dhd = a.data_header
        &gt;&gt;&gt; dlist1 = dhd.index(drange=[50.])          # single index at distance 50 m
        &gt;&gt;&gt; dlist2 = dhd.index(drange=[50., 60.])     # 2 indices at 50 and 60m
        &gt;&gt;&gt; dlist3 = dhd.index(drange=[[dist] for dist in np.arange(50,60.,1.)]) # all indices for distance 50&lt; ..&lt;60 every 1m
        &#34;&#34;&#34;
        from numpy import nanargmin, abs, ndarray
        from ._a1das_exception import DataTypeError, WrongValueError

        if drange is not None and trange is not None:
            raise WrongValueError(&#39;cannot define trange AND drange, select one of two&#39;)

        if drange is not None:
            dtrange=drange
            vec = self[&#39;dist&#39;]
        else:
            dtrange=trange
            vec = self[&#39;time&#39;]

        if isinstance(dtrange, ndarray):
            raise DataTypeError(&#39;range must be a list or tuple&#39;)

        if dtrange is None:
            return [0, -1]

        d1 = nanargmin(abs(vec - dtrange[0]))
        indx = [d1]
        if len(dtrange) == 1:
            indx.append(d1+1)
        else:
            for i in range(1,len(dtrange)):
                indx.append(nanargmin(abs(vec-dtrange[i])))
        return indx


#
# ========================================= CLASS A1File ============================
#
class A1File:
    &#34;&#34;&#34;
    ## Description
    A1File class contains file/socket descriptors to read and convert DAS data from Febus format,
    or H5 reducted file format or data socket stream (ZMQ protocol).

    ## Class content

        A1File.file_header:    file header    (_A1FileHeader class instance)
        A1File.socket_header:  socket header  (_A1SocketHeader class instance)
        A1File.data_header:    metadata       (_A1DataHeader class instance)

    The metadata list is obtained by typing the name of the A1File instance (see example below)

    ## Reading/setting data_header metadata
    Read directly as a dictionnary from a1_file (ex: f[&#39;dt&#39;]) or through data_header (ex: f.data_header[&#39;dt&#39;])

    Set by the set_item method() ex: f.set_item(dt=0.1) or through data_header ex: f.data_header.set_item(dt=0.1)

    ## Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f = a1das.open(&#34;my_filename&#34;)
        &gt;&gt;&gt; f # print metadata header values
        &gt;&gt;&gt; GL = f[&#39;gauge_length&#39;]
        &gt;&gt;&gt; f.set_item(gauge_length=10.)
    &#34;&#34;&#34;
    def __init__(self, file_header=None, socket_header=None, data_header=None):
        # metadata
        self.file_header   = file_header   # _A1FileHeader class instance : io from file
        self.socket_header = socket_header # io from socket
        self.data_header   = data_header   # A1DasDataHeder class instance : some meta data

    def set_item(self, **kwargs):
        &#34;&#34;&#34;
        ##Description
        Update/create a matadata entry in the data_header class dictionnary attached to the A1File

        ##Input
            **kwargs = arbitrary list of key_word = value
        ##Usage example
            &gt;&gt;&gt; import a1das
            &gt;&gt;&gt; f=a1das.open(filename)
            &gt;&gt;&gt; f.set_item(dog_name=&#39;medor&#39;,dog_food=&#39;candies&#39;,dog_age=7)

        &#34;&#34;&#34;
        self.data_header.set_item(kwargs)

    def __getitem__(self, item):
        &#34;&#34;&#34;
        overload [] operator for the A1File class
        &#34;&#34;&#34;
        try:
            return self.data_header._header[item]
        except:
            return None
    #
    # ========================================= READ() ============================
    #
    def read(self, block=None, trange=None, drange=None, ddecim=1, skip=True, verbose=0, **kwargs):
        &#34;&#34;&#34;
        ## Description
        Read data from a Febus/reducted file or a socket directly connected to Febus DAS
        in memory and return a `A1Section` class instance.

        All data are read unless one of the three options is set: block, trange, drange.
        block is exclusive with trange,drange and return data aligned on block limits

        Data are read as float32 and are converted by default as float64 unless specified

        ## Input:
            block = (list), block=[start, end, step]. Read full block of data, from start to end by step.
                [0,0,?] read all blocks
                [] read one block
                default = None
            trange = (list), in sec, trange=[start_time, end_time], select time from start_time to end_time
                default = None
            drange = (list), in meter, drange=[start_position, end_position], select distance from start_position
                to end_position
                default = None
            ddecim = decimation along spatial dimension, (must be a divider of chunck/block size)

            skip = read all blocks/chunck of data (False) or one over 2 (True)
                blocks contains redundant data, skip=True is faster but may yield some errors on block limits

            verbose = verbosity level

            **kwargs= any optionnal supplementary arguments, see below

        ## Return:
        A `A1Section` class instance

        ## Usage example
            &gt;&gt;&gt; import a1das
            &gt;&gt;&gt; f = a1das.open(&#34;my_filename&#34;)
            &gt;&gt;&gt; a1 = f.read(trange=(0.,1800.),drange=(100., 900.),skip=False)

        ## optionnal arguments
            float_type = &#39;float_32&#39; or &#39;float_64&#39; for febus file only
        &#34;&#34;&#34;

        from ._core_febus_file import read_febus_file
        from ._core_reducted_file import read_reducted_file
        from ._core_socket import read_das_socket

        # read from a file (febus or reducted)
        if self.file_header is not None:
            if self.file_header.type == &#39;febus&#39;:
                data_header, data = read_febus_file(self, block, trange, drange, ddecim, skip, verbose=verbose,**kwargs)

            elif self.file_header.type == &#39;reducted&#39;:
                data_header, data = read_reducted_file(self, trange=trange, drange=drange, verbose=verbose,**kwargs)

        # read from a socket
        elif self.socket_header is not None:
            data_header, data = read_das_socket(self, block, drange=drange, ddecim=ddecim,**kwargs)

        else:
            data_header = data = None

        # create A1DSection class instance
        if self.file_header is not None:
            data_header.set_item(filename=self.file_header.filename)

        return A1Section(data_header, data)
    #
    # ========================================= CLOSE() ============================
    #
    def close(self):
        &#34;&#34;&#34;
        Close a das file or socket stream

        &#34;&#34;&#34;
        from ._core_febus_file import close_das_file
        from ._core_socket import close_das_socket

        # On lit depuis un fichier
        if self.file_header:
            close_das_file(self.file_header)
            self.file_header = None

        # On lit depuis un socket
        elif self.socket_header:
            close_das_socket(self.socket_header)
            self.socket_header = None


    #
    # ====================================    PRINT()  =======================================
    #
    def __str__(self, verbose=0):
        &#34;&#34;&#34;
        Display the informations of a Febus DAS hdf5 file, called by print()

        verbose:  = if 1 (default) only acquisition information is printed; if &gt;1, internal HDF5 file structure is printed
        &#34;&#34;&#34;
        
        from io import StringIO
        s = StringIO()

        s.write(&#39;\n&lt;A1File&gt;:&#39;)
        s.write(&#39;\n-----------&#39;)
        if self.file_header is not None:
            s.write(&#39;\nfile_header:&#39;)
            # print file_header part
            s.write(self.file_header.__str__())

        if self.socket_header is not None:
            s.write(&#39;\nsocket_header:&#39;)
            # print socket_header part
            s.write(self.socket_header.__str__())

        # print data_header part
        s.write(&#39;\n\ndata_header:&#39;)
        s.write(self.data_header.__str__())
        return s.getvalue()

    def __repr__(self):
        &#34;&#34;&#34;
        Display the informations of a Febus DAS hdf5 file, called by print()
        verbose:  = if 1 (default) only acquisition information is printed; if &gt;1, internal HDF5 file structure is printed
        &#34;&#34;&#34;
        return self.__str__()


    #
    # ====================================    _GET_TIME_BOUNDS()  =======================================
    #
    # Note O.C:
    #
    # Data are written by block (or chunk) @ Freq_res/1000 Hz (typically 1 Hz),
    # that contains several records
    # One record corresponds to all strain(rate) values along fiber recorded at a specific time
    # Each block contains &#34;bts2&#34; records of data (e.g 1sec) plus additional overlapping
    # The blocks overlap by half their length, (i.e. 1sec in the above example), they are thus 2sec long
    # One quarter (bts4) overlap with the previous block, one quarter (bts4) with the next one
    # The useful part of data, the &lt;record&gt; starts at 1/4 and ends at 3/4 of a block
    #
    #  [ - ~ ~ -]                    block 1
    #       [- ~ ~ -]                block 2
    #          [ - ~ ~ - ]           block 3
    #             .....
    #              [ - ~ ~ - ]       last block
    #
    #      - : unused duplicated time samples, there are bts4 time samples in &#39;-&#39;
    #      ~ : time samples read = &lt;record&gt;, there are bts2 time samples in &#39;~ ~&#39;
    #
    # block_time_size is the number of time samples in a block, bts2 is half of that, bts4 a quarter
    # dt is the time step between sample, i.e, records

    def _get_time_bounds(self, block=None, trange=None, skip=True, align_on_block=False, tdecim=None):
        &#34;&#34;&#34;
        file_header._get_time_bounds(block, trange, skip, align_on_block, tdecim)

        Create block and time indices for reading according to the argument choice

        block    = [first_block, last_block] select data comprised between first_block, last_block (comprised),
                    default = None
        trange   = extract time starting at range[0] to range[1] or everything is trange=None and block = None
        skip     = skip redundant block when reading data (default = True)
        align_on_block = aligned data on start of block &amp; end of block rather than exact time (if trange is set)
        tdecim   = time decimation factor

        return:  first_block,    = first block to be read in the file
                 last_block,     = last block +1 to be read in the file
                 step_block,     = step
                 time_vector_out = vector of absolute time value on output
                 time_indices    = [first, last] indices to be read in the 1st, last and other blocks

        &#34;&#34;&#34;
        #
        from numpy import arange, fix

        nb_block_max = self.file_header.block_info[&#39;nb_block&#39;]  # total number of block in the file
        freq_res = self.file_header.freq_res  # frequency of block writing

        bts = self.file_header.block_info[&#39;time_size&#39;]
        bts2 = int(bts / 2)
        bts4 = int(bts / 4)
        dT = self.data_header[&#39;dt&#39;]
        origin_time = self.data_header[&#39;otime&#39;]

        # origin time of the file is the first sample read by febus (they skip one fourth of the first block)
        offset = bts4 * dT
        #offset_rule = offset
        # origin time of the file is the first sample of the file (this solution according to Gaëtan)
        offset_rule = 0.

        if skip:
            # !!!! if skip  = 2, one can read only an ODD number of blocks
            step_block = 2
            if nb_block_max % 2 == 0:
                nb_block_max = nb_block_max - 1  # The last EVEN block cannot be read
        else:
            # !!!! if skip  = 1, one can read any number of block
            step_block = 1
        #
        # define the read &lt;for&gt; loop indices: first_block, last_block
        #  for i, block in enumerate(range(first_block, last_block, step_block)):
        #
        if not trange:
            if block:
                first_block = block[0]
                last_block = min(block[1] + 1, nb_block_max)
                nb_block = last_block - first_block
            else:
                first_block = 0  # First block index for temporal acquisition
                nb_block = nb_block_max
                last_block = nb_block  # last block index in the reading loop, ie, never reached

            # for skip=2, read one block over 2, we scan an ODD number of block
            # start time is the beginning of the first block
            # !!!!! RECALL than nb_block IS NOT the number of blocks read, but the number of block scanned on the disk
            if skip:
                if nb_block % 2 == 0:
                    nb_block = max(nb_block + 1, nb_block_max)
                    last_block = first_block + nb_block - 1
                from_time = first_block * bts2 * dT
                # Total_time_size = number of time samples that we read in the time series
                total_time_size = (nb_block + 1) * bts2
                # total_time_size = nb_block * bts2 #ModifOC
                # time indices for 1st block, other blocks, last block
                time_indices = [[0, bts], [0, bts], [0, bts]]

            # for skip = 1, read every block, no restriction, but read only half of their size
            # start time is the first quarter of the first block because we don&#39;t want to manage
            # the 1st quarter of block (by laziness...)
            else:
                from_time = first_block * bts2 * dT + bts4 * dT
                total_time_size = nb_block * bts2
                # time indices for 1st block, other blocks, last block
                time_indices = [[bts4, 3 * bts4], [bts4, 3 * bts4], [bts4, 3 * bts4]]
        #
        # read only selected time range
        #
        else:
            from_time = trange[0]
            to_time = trange[1]

            if not skip:
                # check range that was given as argument
                min_time = bts4 * dT
                #min_time = 0.
                if from_time &lt; min_time:
                    from_time = min_time
                max_time = ((nb_block_max * bts2 + bts4) * dT)
                if to_time &gt; max_time:
                    to_time = (nb_block_max * bts2 + bts4) * dT
                    print(&#39;Warning: trange max is to high, set to:&#39;, str(to_time))

                # first_block = int(np.fix(from_time * freq_res))  # index of block containing the start time
                # last_block  = int(np.fix(to_time * freq_res)) + 1  # index of block containing the ending time + 1
                ##first_block = int(fix(from_time * freq_res)) - 1  # index of block containing the start time
                ##last_block = int(fix(to_time * freq_res))  # index of block containing the ending time + 1
                first_block = int(fix((from_time-offset) * freq_res))
                last_block  = int(fix((to_time-offset) * freq_res)) + 1
                if last_block &gt; nb_block_max:
                    last_block = nb_block_max
                nb_block = last_block - first_block

                # round from_time to the start time of the first block that is read
                # time indices for 1st block, other blocks, last block
                # For future use: if we decide not to round to block limits

                if not align_on_block:
                    dt_1 = from_time - (first_block * bts2 + bts4) * dT
                    i_1 = int(dt_1 / dT)
                    dt_last = to_time - ((last_block - 1) * bts2 + bts4) * dT
                    i_last = int(dt_last / dT)
                    if nb_block &gt;1:
                        time_indices = [[bts4 + i_1, 3 * bts4], [bts4, 3 * bts4], [bts4, i_last + bts4]]
                    else:
                        time_indices = [[bts4 + i_1, i_last + bts4], [bts4 + i_1, i_last + bts4], [bts4 + i_1, i_last + bts4]]
                    total_time_size = (nb_block * bts2) - i_1 - (bts2 - i_last)
                else:
                    time_indices = [[bts4, 3 * bts4], [bts4, 3 * bts4], [bts4, 3 * bts4]]
                    from_time = (first_block * bts2 + bts4) * dT
                    # Total_time_size = number of time samples in the time series
                    total_time_size = nb_block * bts2



            else:  # skip = True
                if from_time &lt; 0:
                    from_time = 0
                max_time = ((nb_block_max + 1) * bts2 * dT)
                if to_time &gt; max_time:
                    to_time = max_time

                # first_block = int(np.fix(from_time * freq_res))  # index of block containing the start time
                # last_block  = int(np.fix(to_time * freq_res)) + 1  # index of block containing the ending time
                ##first_block = int(fix(from_time * freq_res)) - 1 # index of block containing the start time
                ##last_block = int(fix(to_time * freq_res))  # index of block containing the ending time + 1
                first_block = int(fix((from_time) * freq_res / 2.))*2
                last_block  = int(fix((to_time) * freq_res / 2.))*2 + 1

                nb_block = last_block - first_block
                if nb_block % 2 == 0:  # Always read an ODD number of block
                    last_block += 1
                    nb_block += 1
                if last_block &gt; nb_block_max:
                    last_block = nb_block_max

                # round from_time to the start time of the first block that is read
                # For future use: if we decide not to round to block limits
                if not align_on_block:
                    # starting time in the first block of the first point
                    dt_1 = from_time - first_block * bts2 * dT
                    i_1 = int(dt_1 / dT)
                    # ending time in the last block of the first point
                    dt_last = to_time - (last_block - 1) * bts2 * dT
                    i_last = int(dt_last / dT)
                    if nb_block &gt; 1:
                        time_indices = [[i_1, bts], [0, bts], [0, i_last]]
                    else:
                        time_indices = [[i_1, i_last], [i_1, i_last], [i_1, i_last]]
                    total_time_size = (nb_block + 1) * bts2 - i_1 - (bts - i_last)
                else:
                    time_indices = [[0, bts], [0, bts], [0, bts]]
                    from_time = first_block * bts2 * dT
                    # Total_time_size = number of time samples in the time series
                    total_time_size = (nb_block + 1) * bts2

        # Create the time vector that contains samples datation
        # decimation can only be performed when reading entire blocks
        # The calling process must ensure that the block size is a multiplier of decimation factor
        # case no decimation
        if tdecim is None or tdecim == 1:
            time_vector_out = arange(0, total_time_size) * dT + from_time #+ origin_time
        # case no time range and time decimation
        elif not trange:
            time_vector_out = arange(0, total_time_size, tdecim) * dT + from_time #+ origin_time
        # case
        else:
            print(&#39;Time decimation is only valid when reading complete file or a block list&#39;)
            time_vector_out = arange(0, total_time_size) * dT + from_time #+ origin_time

        return first_block, last_block, step_block, time_vector_out, time_indices

    #
    # ====================================    _GET_SPACE_BOUND()  =======================================
    #
    def _get_space_bounds(self, drange=None, ddecim=None):
        &#39;&#39;&#39;
        A1File._get_space_bounds(drange, ddecim)

        :param drange: extract positions from from_to_position[0] to from_to_position[1], if not used set to None
        :param ddecim: space decimation step, if not used set to 1

        :return: distance_fiber_out, distance_indices, distance_fiber_in
                 distance_vector selected, array of distance indices in the input distance_vector
        &#39;&#39;&#39;
        from numpy import linspace, nanargmin

        ZI_start = self.data_header[&#39;ospace&#39;]
        dX = self.data_header[&#39;dx&#39;]
        distance_fiber_in = linspace(0, self.data_header[&#39;nspace&#39;] - 1, self.data_header[&#39;nspace&#39;]) * dX + ZI_start
        #ZI_end = distance_fiber_in[-1]

        # extract everything
        if not drange:
            first_point = 0  # index for 1st point
            last_point = self.data_header[&#39;nspace&#39;] - 1  # index for last point

        # extract a selected part
        else:
            # check range given as argument
            from_position = drange[0]
            to_position = drange[1]
            if from_position &lt; distance_fiber_in[0]:
                from_position = distance_fiber_in[0]
            if to_position &gt; distance_fiber_in[-1]:
                to_position = distance_fiber_in[-1]
                print(&#39;Warning: drange max is too high, set to &#39;, str(to_position))

            # set indices
            first_point = int(nanargmin(abs(distance_fiber_in- from_position)))
            last_point  = int(nanargmin(abs(distance_fiber_in- to_position)))

        # distance_length = Total_space_size
        # distance_start = First_point
        # distance_end = distance_start + distance_length
        distance_fiber_out = distance_fiber_in[
                             first_point:last_point + 1:ddecim]  # add 1 because last index is excluded
        distance_indices = range(first_point, last_point + 1, ddecim)  # add 1 because last index is excluded

        return distance_fiber_out, distance_indices, distance_fiber_in

    #
    # ====================================   SET_OTIME_FROM_FILENAME()  =======================================
    #
    def set_otime_from_filename(self, offset=0., prefix=None):
        &#34;&#34;&#34;
        ##Description
        Set data header origin time from the filename assuming Febus convention on the filename
        ex: SR_2021-08-26_14-32-39_UTC.h5.
        This call affect the origin time to file header and is propagated to all subsequent A1File.read() call
        This does not affect the values of the &lt;time&gt; vector which always refer to the origin (ie starting) time
        ##Input
            offset = a time offset to add/substract from the filename information
            prefix = a prefix ending by &#34;_&#34; in case the filename do not follow Febus convention (SR_, RAW_, S_, ...)
        &#34;&#34;&#34;
        from datetime import timezone, datetime
        from ._a1das_exception import WrongValueError

        name = self.file_header.filename
        # expected to be of the form SR_2021-08-26_14-32-39_UTC.h5
        if prefix is None:
            start = name.find(&#34;_&#34;)
            ofs = 1
        else:
            start = name.find(prefix)
            ofs = len(prefix)

        if start == -1:
            raise WrongValueError(&#39;could not set origin time from filename, check filename and/or prefix&#39;)
            return
        end = name.find(&#34;_UTC&#34;)
        s = name[start+ofs:end]
        # convert from string
        try:
            d = datetime.strptime(s, &#34;%Y-%m-%d_%H-%M-%S&#34;)
        except:
            raise ValueError(&#39;wrong date-time format, check file prefix&#39;)

        # convert to UTC
        dd = datetime(d.year, d.month, d.day, d.hour, d.minute, d.second, tzinfo=timezone.utc)
        # convert to Posix
        self.data_header.set_item(otime=dd.timestamp()+offset)

    def time(self):
        &#34;&#34;&#34;
        ## Description
        Return the time vector defined in the A1File data_header, i.e. same as f[&#39;time&#39;]
        &#34;&#34;&#34;
        return self.data_header[&#39;time&#39;]

    def dist(self):
        &#34;&#34;&#34;
        ## Description
        Return the distance vector defined in the A1File data_header, i.e. same as f[&#39;dist&#39;]
        &#34;&#34;&#34;
        return self.data_header[&#39;dist&#39;]

    #
    # ========================================= CLASS A1SECTION ============================
    #
class A1Section:
    &#34;&#34;&#34;
    ## Description
    A1Section class contains das data and metadata read from file or TCP stream

    ## Class content

        A1Section.data:         2D float array (ndarray of shape [ntime x nspace] or [nspace x ntime])
        A1Section.data_header   metadata       (_A1DataHeader class instance)


    ## Reading/setting data_header metadata
    Read directly as a dictionnary from a1_section ex: a1[&#39;dt&#39;] or through data_header ex: a1.data_header[&#39;dt&#39;]

    Set by the set_item method() ex: a1.set_item(dt=0.1) or through data_header ex: a1.data_header.set_item(dt=0.1)
    ##Usage example
        &gt;&gt;&gt;import a1das
        &gt;&gt;&gt;f=a1das.open(filename)   # open file
        &gt;&gt;&gt;a1 = f.read()            # read section
        &gt;&gt;&gt;a1                       # print header values
        &gt;&gt;&gt;time_step=a1[&#39;dt&#39;]       # get time step
        &gt;&gt;&gt;a1.set_item(dt=0.1)      # set time step

    &#34;&#34;&#34;
    def __init__(self, dhd=None, data=None):
        self.data_header = dhd    # dictionnary of header values
        self.data = data          # numpy 2D ndarray.
                                  # If data_header[&#39;axis&#39;] = &#39;time_x_space&#39; first dimension is time
                                  # If data_header[&#39;axis&#39;] = &#39;space_x_time&#39; first dimension is space

    def time(self):
        &#34;&#34;&#34;
        ## Description
        Return the time vector defined in the &lt;A1Section&gt; data_header, i.e. shortcut for a1.data_header[&#39;time&#39;]
        &#34;&#34;&#34;
        return self.data_header[&#39;time&#39;]

    def dist(self):
        &#34;&#34;&#34;
        ## Description
        Return the distance vector defined in the &lt;A1Section&gt; data_header, i.e. shortcut for a1.data_header[&#39;dist&#39;]
        &#34;&#34;&#34;
        return self.data_header[&#39;dist&#39;]

    def otime(self):
        &#34;&#34;&#34;
        ##Description
        Return the UTC origin (or start) time of the section
        in two formats: Posix time and string

        ##Return
        posix_otime, string_otime
        &#34;&#34;&#34;
        from datetime import datetime, timezone
        time = self[&#39;time&#39;]   # could read otime too
        otime=time[0]

        return otime, datetime.fromtimestamp(otime, tz=timezone.utc).strftime(&#39;%Y:%M:%d-%H:%M:%S.%f&#39;)


    def __str__(self):
        from io import StringIO
        s = StringIO()

        s.write(&#39;\n&lt;A1Section&gt;:&#39;)
        s.write(&#39;\n--------------&#39;)
        s.write(&#39;\ndata: \nndarray data[&#39;+str(self.data_header[&#39;ntime&#39;])+&#39;x&#39;+str(self.data_header[&#39;nspace&#39;])+&#39;]\n&#39;)
        # print file_header part
        s.write(&#39;\ndata_header: &#39;)
        s.write(self.data_header.__str__())

        return s.getvalue()

    def __repr__(self):
        return self.__str__()

    def set_item(self, **kwargs):
        &#34;&#34;&#34;
        ##Description
        Update/create a matadata entry in the data_header class dictionnary attached to A1Section

        ##Input
            **kwargs = arbitrary list of key_word = value
        ##Usage example
            &gt;&gt;&gt; import a1das
            &gt;&gt;&gt; f=a1das.open(filename)
            &gt;&gt;&gt; a=f.read()
            &gt;&gt;&gt; a.set_item(cat_name=&#39;medor&#39;,cat_food=&#39;candies&#39;,cat_age=7)

        &#34;&#34;&#34;
        self.data_header.set_item(kwargs)
        
    def __getitem__(self, item):
        &#34;&#34;&#34;
        overload [] operator for the A1Section class
        &#34;&#34;&#34;
        try:
            return self.data_header._header[item]
        except:
            return None
    #
    # ====================================   SET_OTIME_FROM_FILENAME()  =======================================
    #
    def set_otime_from_filename(self, offset=0., prefix=None):
        &#34;&#34;&#34;
        ##Description
        Set data header origin time from the filename assuming Febus convention on the filename
        ex: SR_2021-08-26_14-32-39_UTC.h5.
        This call affect the origin time to file header and is propagated to all subsequent A1File.read() call
        This does not affect the values of the &lt;time&gt; vector which always refer to the origin (ie starting) time

        ##Input
            offset = a time offset to add/substract from the filename information
            prefix = a prefix ending by &#34;_&#34; in case the filename do not follow Febus convention (SR_, RAW_, S_, ...)
        &#34;&#34;&#34;
        from datetime import timezone, datetime
        from ._a1das_exception import WrongValueError

        if &#39;filename&#39; in self.data_header._header.keys():
            name = self.data_header[&#39;filename&#39;]
            # expected to be of the form SR_2021-08-26_14-32-39_UTC.h5
            if prefix is None:
                start = name.find(&#34;_&#34;)
                ofs = 1
            else:
                start = name.find(prefix)
                ofs = len(prefix)

            if start == -1:
                raise WrongValueError(&#39;could not set origin time from filename, check filename and/or prefix&#39;)
                return
            end = name.find(&#34;_UTC&#34;)
            s = name[start+ofs:end]
            # convert from string
            try:
                d = datetime.strptime(s, &#34;%Y-%m-%d_%H-%M-%S&#34;)
            except:
                raise ValueError(&#39;wrong date-time format, check file prefix&#39;)

            # convert to UTC
            dd = datetime(d.year,d.month,d.day,d.hour,d.minute,d.second, tzinfo=timezone.utc)
            # convert to Posix
            self.data_header.set_item(otime=dd.timestamp()+offset)
        else:
            raise WrongValueError(&#39;&lt;filename&gt; is not defined in data header&#39;)

    #
    # ====================================   OBSPY_STREAM()  =======================================
    #
    def obspy_stream(self, drange=None, station_name=None):
        &#34;&#34;&#34;
        ##Description
        Return an obspy stream from a DAS section with optional spatial range drange

        ##Input
            drange: = (dmin, dmax) list or tuple with minimal and maximal distance in meter
        ##Return
            An obspy stream
        &#34;&#34;&#34;
        from obspy.core import Stream, Trace, UTCDateTime
        from ._a1das_exception import WrongValueError

        st = Stream()
        if drange is None:
            s0=0
            s1=self[&#39;nspace&#39;]
        else:
            s = self.index(drange)
            s0 = s[0]
            s1 = s[1]+1

        dist = self[&#39;dist&#39;]
        time = self[&#39;time&#39;]
        if station_name is None:
            station_name = &#39;DAS&#39;
        for i in range(s0, s1):
            header = {&#39;npts&#39;: self.data_header[&#39;ntime&#39;],
                      &#39;station&#39;: station_name,
                      &#39;starttime&#39;: UTCDateTime(self.data_header[&#39;otime&#39;]+time[0]),
                      #&#39;sampling_rate&#39;: 1./float64(self.data_header[&#39;dt&#39;]),
                      &#39;location&#39;: str(int(dist[i]))+&#39;m&#39;,
                      &#39;channel&#39;: &#39;S&#39;,
                      &#39;delta&#39; : self.data_header[&#39;dt&#39;]
                      }
            if self.data_header[&#39;data_axis&#39;] == &#39;time_x_space&#39;:
                st.append(Trace(data=self.data[:,i], header=header))
            elif self.data_header[&#39;data_axis&#39;] == &#39;space_x_time&#39;:
                st.append(Trace(data=self.data[i,:], header=header))
            else:
                raise WrongValueError(&#39;&lt;data_axis&gt; header field is neither &lt;time_x_space&gt; nor &lt;space_x_time&gt;&#39;)
        return st

    # ====================================   INDEX()  =======================================
    #
    def index(self, drange=None, trange=None):
        &#34;&#34;&#34;
        ## Description
        Return the index or list of indices that correspond(s) to the list of distance(resp. time) range
        in the &#39;distance&#39; vector (resp. time vector)

        ## Input
        !!!!! Only one of trange or drange can be given

        drange = [unique_dist]; [dist_min, dist_max]; [d1, d2, ... dN]  (default = None)

        trange = [unique_time]; [time_min, time_max]; [t1, t2, ... tN]  (default = None)

        ## Return
        A list of indices that matches the given range in the A1Section.data_header[&#39;dist&#39;] or
        A1Section.data_header[&#39;time&#39;] vectors

        ## Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f=open(&#39;filename&#39;)
        &gt;&gt;&gt; a=f.read()
        &gt;&gt;&gt; dlist1 = a.index(drange=[50.])          # single index at distance 50 m
        &gt;&gt;&gt; dlist1 = a.index(50.)                   # single index at distance 50 m
        &gt;&gt;&gt; dlist2 = a.index(drange=[50., 60.])     # 2 indices at 50m and 60m
        &gt;&gt;&gt; dlist3 = a.index(drange=[[dist] for dist in np.arange(50,60.,1.)]) # all indices for distance 50&lt; ..&lt;60 every 1m
        &gt;&gt;&gt; tlist = a.index(trange=[10.,11.])       # time indices for time between 10. and 20s after 1st sample
        &#34;&#34;&#34;
        from numpy import nanargmin, abs, ndarray
        from ._a1das_exception import DataTypeError, WrongValueError

        if drange is not None and trange is not None:
            raise WrongValueError(&#39;cannot define trange AND drange, select one of two&#39;)

        if drange is None and trange is None:
            raise WrongValueError(&#39;Please define one of drange(distance range) or trange (time range)&#39;)

        if drange is not None:
            dtrange=drange
            vec = self.data_header[&#39;dist&#39;]
        else:
            dtrange=trange
            vec = self.data_header[&#39;time&#39;]

        if isinstance(dtrange, ndarray):
            raise DataTypeError(&#39;range must be a list or tuple&#39;)

        if isinstance(dtrange,float):
            dtrange=[dtrange]

        if dtrange is None:
            return [0, -1]

        d1 = nanargmin(abs(vec - dtrange[0]))
        indx = [d1]
        if len(dtrange) == 1:
            indx.append(d1+1)
        else:
            for i in range(1,len(dtrange)):
                indx.append(nanargmin(abs(vec-dtrange[i])))
        return indx
    #
    # ====================================   PLOT()  =======================================
    #
    def plot(self, fig=None, clip=100, splot=(1, 1, 1), title=&#39;&#39;, max=100, amax=None, variable_area=False, drange=None, trange=None, redraw=None):
        &#34;&#34;&#34;
        ##Description
        Produce a vector plot of the das section, optionnaly with variable area
        ##Input
            fig= figure handle (default None)
            clip= (int) clip amplitude at clip% of the max amplitude (default 100%)
            splot= (tupple) plot as a subplot (default subplot(1,1,1))
            title= (str) figure title (default None)
            max= (int) maximum number of traces on the plot (default 100)
            amax= maximum amplitude for clipping if not using clip percentage (default None)
            variable_area= (bool) plot with variable_are (half wiggle is filled in black) (default False)
            drange= (tupple) distance range [dmin, dmax]
            trange= (tupple) time range [tmin, tmax]
            redraw = {lines} redraw lines of a precedent figure  or None for new plot, requires fig argument

        ##Return
            figure_handle, curve_list

        ##Usage example
            &gt;&gt;&gt;import a1das
            &gt;&gt;&gt;f=a1das.open(filename)
            &gt;&gt;&gt;a1=f.read()
            &gt;&gt;&gt;a1.plot(clip=50,variable_area=True)
        &#34;&#34;&#34;
        from a1das._plot import plot
        from ._a1das_exception import ReadDataError

        if self.data is None:
            raise ReadDataError(&#39;Hum Hum, read data before plotting ...&#39;)

        fig, redraw = plot(self,fig, clip, splot, title, max, amax, variable_area, drange, trange, redraw)

        return fig, redraw
    #
    # ====================================   RPLOT()  =======================================
    #
    def rplot(self, fig=None, cmap=&#39;RdBu&#39;, vrange=None, splot=(1, 1, 1), title=&#39;&#39;, drange=None, trange=None):
        &#34;&#34;&#34;
        ##Description
        Produce a raster plot of the das section
        ##Input
            fig= figure handle (default None)
            cmap= colormap (default=RdBu)
            vrange= trace amplitude range (default None)
            splot= plot as a subplot (default subplot(1,1,1))
            title= figure title (default None)
            drange= distance range
            trange= time range

        ## Return
            figure_handle, axes_handle

        ##Usage example
            &gt;&gt;&gt;import a1das
            &gt;&gt;&gt;f=a1das.open(filename)
            &gt;&gt;&gt;a1=f.read()
            &gt;&gt;&gt;a1.rplot()
        &#34;&#34;&#34;
        from a1das._plot import rplot
        from ._a1das_exception import ReadDataError

        if self.data is None:
            raise ReadDataError(&#39;Hum Hum, read data before plotting ...&#39;)

        fig, ax = rplot(self,fig, cmap, vrange, splot, title, drange, trange)

        return fig, ax

    def save(self,filename):
        &#34;&#34;&#34;
        ## Description
        a.save(filename)

        Save a `A1Section` that has been read, extracted or converted from stream or files into the reducted file format.

        ## Input
        filename= a name for the hdf5 file that contains the reducted file

        ## Usage example
            &gt;&gt;&gt; import a1das
            &gt;&gt;&gt; f = a1das.open(&#39;my_filename&#39;, format=&#39;febus&#39;)
            &gt;&gt;&gt; a = f.read(trange=(tmin,tmax), drange=(dmin,dmax), skip=False) # read and extract a subportion of the original file
            &gt;&gt;&gt; a.save(&#39;new_section&#39;) # &#39;a&#39; can be read later using the same a1das.open() and f.read() functions
            &gt;&gt;&gt; f.close()

        &#34;&#34;&#34;
        from ._core_reducted_file import _save_reducted_file
        _save_reducted_file(self,filename)

    def concat(self, b):
        &#34;&#34;&#34;
        ## Description
            a.concat(b): Concatenate section b behind section a along the fast axis
            if a and b are ordered as [space x time], fast axis is time and on obtain a new section [ space x 2*time]
            if a and b are ordered as [time x space], not implemented

        ## Return
            a new section
        &#34;&#34;&#34;
        import numpy as np
        from ._a1das_exception import DataTypeError

        if self[&#39;data_axis&#39;] != &#39;time_x_space&#39; or b[&#39;data_axis&#39;] != &#39;time_x_space&#39;:
            raise DataTypeError(&#39;section must be ordered with data as time x space&#39;)

        time_a = self[&#39;time&#39;]
        time_b = b[&#39;time&#39;]

        nspace_a = self[&#39;nspace&#39;]
        nspace_b = b[&#39;nspace&#39;]
        if nspace_a != nspace_b:
            raise DataTypeError(&#39;concat: different spatial spacing&#39;)

        dta = self[&#39;dt&#39;]
        dtb = b[&#39;dt&#39;]
        if dta != dtb:
            raise DataTypeError(&#39;concat failed, different sampling rate&#39;)


        # Create new section
        data_header = self.data_header.copy()
        data_header.set_item(ntime=self[&#39;ntime&#39;]+b[&#39;ntime&#39;])
        data_header.set_item(time=np.concatenate((time_a,time_b)))
        newdata = np.vstack((self.data, b.data))

        return A1Section(data_header, newdata)

#
# ========================================= OPEN()  ============================
#
def open(filename, format=None):
    &#34;&#34;&#34;
    ## Description
    f=open(&#39;path&#39;,format)  where format = &#39;febus&#39;, &#39;reducted&#39;, &#39;socket&#39;.

    Open a Febus das file, a reducted Hdf5 file or a socket stream on a DAS Febus interrogator and return an `A1File` instance

    ## Input
    filename= a filename or a socket address in the form &#34;tcp://ip_address:port&#34;

    format = one of &#39;febus&#39;, &#39;reducted&#39;, &#39;socket&#39;. If not supplied, the function try to determine it automatically

    The socket address can be formatted using the a1das.tcp_address utility

    ## Return
    a `A1File` class instance

    ## Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f = a1das.open(&#39;my_filename&#39;, format=&#39;reducted&#39;)
        &gt;&gt;&gt; f2 = a1das.open(a1das.tcp_address(&#39;128.0.0.1&#39;,6667), format=&#39;socket&#39;)

    &#34;&#34;&#34;
    from ._core_febus_file import open_febus_file
    from ._core_reducted_file import open_reducted_file
    from ._core_socket import open_das_socket
    from ._a1das_exception import FileFormatError, WrongValueError

    if format == &#39;febus&#39; or format is None:
        try:
            file_header, data_header = open_febus_file(filename)
            return A1File(file_header=file_header, data_header=data_header)
        except (KeyError, OSError, AttributeError):
            print(&#39;not in febus format&#39;)
            pass

    if format == &#39;reducted&#39; or format is None:
        try:
            file_header, data_header = open_reducted_file(filename)
            return A1File(file_header=file_header, data_header=data_header)
        except (FileFormatError, OSError):
            print(&#39;not in reducted format&#39;)
            pass

    if format == &#39;socket&#39; or format is None:
        try:
            socket_header, data_header = open_das_socket(filename)
            return A1File(socket_header=socket_header, data_header =data_header)
        except:
            raise FileFormatError(&#39;Cannot open &lt;Febus&gt;, &lt;reducted&gt; or &lt;socket&gt; file format&gt;&#39;)

    # if we are here, some problem occured: wrong format argument for instance
    if format is not None:
        raise WrongValueError(&#34; could not open file&lt;&#34;+filename+&#34;&gt;, wrong format argument?&#34;)

def tcp_address(address=&#39;127.0.0.1&#39;, port=6667):
    &#34;&#34;&#34;
    Return a string of the form &lt;tcp://address:port&gt; from an IP address and a port number
    input:
        address = IP adress as a string, default to &#39;127.0.0.1&#39;
        port = IP port default to 6667
    &#34;&#34;&#34;
    return &#34;tcp://%s:%d&#34; % (address, port)
#
# ========================================= private stuff ===========================
#
def __visit_item__(name, node):
    &#34;&#34;&#34;
    called by f.visititems()
    &#34;&#34;&#34;
    import h5py

    if isinstance(node, h5py.Dataset):
        # node is a dataset
        print(&#39;DATASET : &#39;, node.name)
        print(&#39;   Size :&#39;, node.size)
        print(&#39;   MaxSize : &#39;, node.maxshape)
        print(&#39;   dtype : &#39;, node.dtype)
        print(&#39;   chunkSize : &#39;, node.chunks)

    else:
        # node is a group
        # list all attributes keys (it&#39;s a dict.)
        print(&#39;GROUP: &#39;, node.name)
        print(&#39;Attributes: &#39;)
        for key in node.attrs.keys():
            print(&#39;   &#39;, key, node.attrs[key])
    #
    # display structure of hdf5 file on standard output
    #


def __display__(f):
    f.visititems(__visit_item__)


# Needed for compatibility with 2.7
# f.visit() can&#39;t call directly print in 2.7, but can call myprint()
def __myprint__(x):
    print(x)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="a1das.core.open"><code class="name flex">
<span>def <span class="ident">open</span></span>(<span>filename, format=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>f=open('path',format)
where format = 'febus', 'reducted', 'socket'.</p>
<p>Open a Febus das file, a reducted Hdf5 file or a socket stream on a DAS Febus interrogator and return an <code><a title="a1das.core.A1File" href="#a1das.core.A1File">A1File</a></code> instance</p>
<h2 id="input">Input</h2>
<p>filename= a filename or a socket address in the form "tcp://ip_address:port"</p>
<p>format = one of 'febus', 'reducted', 'socket'. If not supplied, the function try to determine it automatically</p>
<p>The socket address can be formatted using the a1das.tcp_address utility</p>
<h2 id="return">Return</h2>
<p>a <code><a title="a1das.core.A1File" href="#a1das.core.A1File">A1File</a></code> class instance</p>
<h2 id="usage-example">Usage example</h2>
<pre><code>&gt;&gt;&gt; import a1das
&gt;&gt;&gt; f = a1das.open('my_filename', format='reducted')
&gt;&gt;&gt; f2 = a1das.open(a1das.tcp_address('128.0.0.1',6667), format='socket')
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def open(filename, format=None):
    &#34;&#34;&#34;
    ## Description
    f=open(&#39;path&#39;,format)  where format = &#39;febus&#39;, &#39;reducted&#39;, &#39;socket&#39;.

    Open a Febus das file, a reducted Hdf5 file or a socket stream on a DAS Febus interrogator and return an `A1File` instance

    ## Input
    filename= a filename or a socket address in the form &#34;tcp://ip_address:port&#34;

    format = one of &#39;febus&#39;, &#39;reducted&#39;, &#39;socket&#39;. If not supplied, the function try to determine it automatically

    The socket address can be formatted using the a1das.tcp_address utility

    ## Return
    a `A1File` class instance

    ## Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f = a1das.open(&#39;my_filename&#39;, format=&#39;reducted&#39;)
        &gt;&gt;&gt; f2 = a1das.open(a1das.tcp_address(&#39;128.0.0.1&#39;,6667), format=&#39;socket&#39;)

    &#34;&#34;&#34;
    from ._core_febus_file import open_febus_file
    from ._core_reducted_file import open_reducted_file
    from ._core_socket import open_das_socket
    from ._a1das_exception import FileFormatError, WrongValueError

    if format == &#39;febus&#39; or format is None:
        try:
            file_header, data_header = open_febus_file(filename)
            return A1File(file_header=file_header, data_header=data_header)
        except (KeyError, OSError, AttributeError):
            print(&#39;not in febus format&#39;)
            pass

    if format == &#39;reducted&#39; or format is None:
        try:
            file_header, data_header = open_reducted_file(filename)
            return A1File(file_header=file_header, data_header=data_header)
        except (FileFormatError, OSError):
            print(&#39;not in reducted format&#39;)
            pass

    if format == &#39;socket&#39; or format is None:
        try:
            socket_header, data_header = open_das_socket(filename)
            return A1File(socket_header=socket_header, data_header =data_header)
        except:
            raise FileFormatError(&#39;Cannot open &lt;Febus&gt;, &lt;reducted&gt; or &lt;socket&gt; file format&gt;&#39;)

    # if we are here, some problem occured: wrong format argument for instance
    if format is not None:
        raise WrongValueError(&#34; could not open file&lt;&#34;+filename+&#34;&gt;, wrong format argument?&#34;)</code></pre>
</details>
</dd>
<dt id="a1das.core.tcp_address"><code class="name flex">
<span>def <span class="ident">tcp_address</span></span>(<span>address='127.0.0.1', port=6667)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a string of the form <tcp://address:port> from an IP address and a port number
input:
address = IP adress as a string, default to '127.0.0.1'
port = IP port default to 6667</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tcp_address(address=&#39;127.0.0.1&#39;, port=6667):
    &#34;&#34;&#34;
    Return a string of the form &lt;tcp://address:port&gt; from an IP address and a port number
    input:
        address = IP adress as a string, default to &#39;127.0.0.1&#39;
        port = IP port default to 6667
    &#34;&#34;&#34;
    return &#34;tcp://%s:%d&#34; % (address, port)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="a1das.core.A1File"><code class="flex name class">
<span>class <span class="ident">A1File</span></span>
<span>(</span><span>file_header=None, socket_header=None, data_header=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>A1File class contains file/socket descriptors to read and convert DAS data from Febus format,
or H5 reducted file format or data socket stream (ZMQ protocol).</p>
<h2 id="class-content">Class content</h2>
<pre><code>A1File.file_header:    file header    (_A1FileHeader class instance)
A1File.socket_header:  socket header  (_A1SocketHeader class instance)
A1File.data_header:    metadata       (_A1DataHeader class instance)
</code></pre>
<p>The metadata list is obtained by typing the name of the A1File instance (see example below)</p>
<h2 id="readingsetting-data_header-metadata">Reading/setting data_header metadata</h2>
<p>Read directly as a dictionnary from a1_file (ex: f['dt']) or through data_header (ex: f.data_header['dt'])</p>
<p>Set by the set_item method() ex: f.set_item(dt=0.1) or through data_header ex: f.data_header.set_item(dt=0.1)</p>
<h2 id="usage-example">Usage example</h2>
<pre><code>&gt;&gt;&gt; import a1das
&gt;&gt;&gt; f = a1das.open("my_filename")
&gt;&gt;&gt; f # print metadata header values
&gt;&gt;&gt; GL = f['gauge_length']
&gt;&gt;&gt; f.set_item(gauge_length=10.)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class A1File:
    &#34;&#34;&#34;
    ## Description
    A1File class contains file/socket descriptors to read and convert DAS data from Febus format,
    or H5 reducted file format or data socket stream (ZMQ protocol).

    ## Class content

        A1File.file_header:    file header    (_A1FileHeader class instance)
        A1File.socket_header:  socket header  (_A1SocketHeader class instance)
        A1File.data_header:    metadata       (_A1DataHeader class instance)

    The metadata list is obtained by typing the name of the A1File instance (see example below)

    ## Reading/setting data_header metadata
    Read directly as a dictionnary from a1_file (ex: f[&#39;dt&#39;]) or through data_header (ex: f.data_header[&#39;dt&#39;])

    Set by the set_item method() ex: f.set_item(dt=0.1) or through data_header ex: f.data_header.set_item(dt=0.1)

    ## Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f = a1das.open(&#34;my_filename&#34;)
        &gt;&gt;&gt; f # print metadata header values
        &gt;&gt;&gt; GL = f[&#39;gauge_length&#39;]
        &gt;&gt;&gt; f.set_item(gauge_length=10.)
    &#34;&#34;&#34;
    def __init__(self, file_header=None, socket_header=None, data_header=None):
        # metadata
        self.file_header   = file_header   # _A1FileHeader class instance : io from file
        self.socket_header = socket_header # io from socket
        self.data_header   = data_header   # A1DasDataHeder class instance : some meta data

    def set_item(self, **kwargs):
        &#34;&#34;&#34;
        ##Description
        Update/create a matadata entry in the data_header class dictionnary attached to the A1File

        ##Input
            **kwargs = arbitrary list of key_word = value
        ##Usage example
            &gt;&gt;&gt; import a1das
            &gt;&gt;&gt; f=a1das.open(filename)
            &gt;&gt;&gt; f.set_item(dog_name=&#39;medor&#39;,dog_food=&#39;candies&#39;,dog_age=7)

        &#34;&#34;&#34;
        self.data_header.set_item(kwargs)

    def __getitem__(self, item):
        &#34;&#34;&#34;
        overload [] operator for the A1File class
        &#34;&#34;&#34;
        try:
            return self.data_header._header[item]
        except:
            return None
    #
    # ========================================= READ() ============================
    #
    def read(self, block=None, trange=None, drange=None, ddecim=1, skip=True, verbose=0, **kwargs):
        &#34;&#34;&#34;
        ## Description
        Read data from a Febus/reducted file or a socket directly connected to Febus DAS
        in memory and return a `A1Section` class instance.

        All data are read unless one of the three options is set: block, trange, drange.
        block is exclusive with trange,drange and return data aligned on block limits

        Data are read as float32 and are converted by default as float64 unless specified

        ## Input:
            block = (list), block=[start, end, step]. Read full block of data, from start to end by step.
                [0,0,?] read all blocks
                [] read one block
                default = None
            trange = (list), in sec, trange=[start_time, end_time], select time from start_time to end_time
                default = None
            drange = (list), in meter, drange=[start_position, end_position], select distance from start_position
                to end_position
                default = None
            ddecim = decimation along spatial dimension, (must be a divider of chunck/block size)

            skip = read all blocks/chunck of data (False) or one over 2 (True)
                blocks contains redundant data, skip=True is faster but may yield some errors on block limits

            verbose = verbosity level

            **kwargs= any optionnal supplementary arguments, see below

        ## Return:
        A `A1Section` class instance

        ## Usage example
            &gt;&gt;&gt; import a1das
            &gt;&gt;&gt; f = a1das.open(&#34;my_filename&#34;)
            &gt;&gt;&gt; a1 = f.read(trange=(0.,1800.),drange=(100., 900.),skip=False)

        ## optionnal arguments
            float_type = &#39;float_32&#39; or &#39;float_64&#39; for febus file only
        &#34;&#34;&#34;

        from ._core_febus_file import read_febus_file
        from ._core_reducted_file import read_reducted_file
        from ._core_socket import read_das_socket

        # read from a file (febus or reducted)
        if self.file_header is not None:
            if self.file_header.type == &#39;febus&#39;:
                data_header, data = read_febus_file(self, block, trange, drange, ddecim, skip, verbose=verbose,**kwargs)

            elif self.file_header.type == &#39;reducted&#39;:
                data_header, data = read_reducted_file(self, trange=trange, drange=drange, verbose=verbose,**kwargs)

        # read from a socket
        elif self.socket_header is not None:
            data_header, data = read_das_socket(self, block, drange=drange, ddecim=ddecim,**kwargs)

        else:
            data_header = data = None

        # create A1DSection class instance
        if self.file_header is not None:
            data_header.set_item(filename=self.file_header.filename)

        return A1Section(data_header, data)
    #
    # ========================================= CLOSE() ============================
    #
    def close(self):
        &#34;&#34;&#34;
        Close a das file or socket stream

        &#34;&#34;&#34;
        from ._core_febus_file import close_das_file
        from ._core_socket import close_das_socket

        # On lit depuis un fichier
        if self.file_header:
            close_das_file(self.file_header)
            self.file_header = None

        # On lit depuis un socket
        elif self.socket_header:
            close_das_socket(self.socket_header)
            self.socket_header = None


    #
    # ====================================    PRINT()  =======================================
    #
    def __str__(self, verbose=0):
        &#34;&#34;&#34;
        Display the informations of a Febus DAS hdf5 file, called by print()

        verbose:  = if 1 (default) only acquisition information is printed; if &gt;1, internal HDF5 file structure is printed
        &#34;&#34;&#34;
        
        from io import StringIO
        s = StringIO()

        s.write(&#39;\n&lt;A1File&gt;:&#39;)
        s.write(&#39;\n-----------&#39;)
        if self.file_header is not None:
            s.write(&#39;\nfile_header:&#39;)
            # print file_header part
            s.write(self.file_header.__str__())

        if self.socket_header is not None:
            s.write(&#39;\nsocket_header:&#39;)
            # print socket_header part
            s.write(self.socket_header.__str__())

        # print data_header part
        s.write(&#39;\n\ndata_header:&#39;)
        s.write(self.data_header.__str__())
        return s.getvalue()

    def __repr__(self):
        &#34;&#34;&#34;
        Display the informations of a Febus DAS hdf5 file, called by print()
        verbose:  = if 1 (default) only acquisition information is printed; if &gt;1, internal HDF5 file structure is printed
        &#34;&#34;&#34;
        return self.__str__()


    #
    # ====================================    _GET_TIME_BOUNDS()  =======================================
    #
    # Note O.C:
    #
    # Data are written by block (or chunk) @ Freq_res/1000 Hz (typically 1 Hz),
    # that contains several records
    # One record corresponds to all strain(rate) values along fiber recorded at a specific time
    # Each block contains &#34;bts2&#34; records of data (e.g 1sec) plus additional overlapping
    # The blocks overlap by half their length, (i.e. 1sec in the above example), they are thus 2sec long
    # One quarter (bts4) overlap with the previous block, one quarter (bts4) with the next one
    # The useful part of data, the &lt;record&gt; starts at 1/4 and ends at 3/4 of a block
    #
    #  [ - ~ ~ -]                    block 1
    #       [- ~ ~ -]                block 2
    #          [ - ~ ~ - ]           block 3
    #             .....
    #              [ - ~ ~ - ]       last block
    #
    #      - : unused duplicated time samples, there are bts4 time samples in &#39;-&#39;
    #      ~ : time samples read = &lt;record&gt;, there are bts2 time samples in &#39;~ ~&#39;
    #
    # block_time_size is the number of time samples in a block, bts2 is half of that, bts4 a quarter
    # dt is the time step between sample, i.e, records

    def _get_time_bounds(self, block=None, trange=None, skip=True, align_on_block=False, tdecim=None):
        &#34;&#34;&#34;
        file_header._get_time_bounds(block, trange, skip, align_on_block, tdecim)

        Create block and time indices for reading according to the argument choice

        block    = [first_block, last_block] select data comprised between first_block, last_block (comprised),
                    default = None
        trange   = extract time starting at range[0] to range[1] or everything is trange=None and block = None
        skip     = skip redundant block when reading data (default = True)
        align_on_block = aligned data on start of block &amp; end of block rather than exact time (if trange is set)
        tdecim   = time decimation factor

        return:  first_block,    = first block to be read in the file
                 last_block,     = last block +1 to be read in the file
                 step_block,     = step
                 time_vector_out = vector of absolute time value on output
                 time_indices    = [first, last] indices to be read in the 1st, last and other blocks

        &#34;&#34;&#34;
        #
        from numpy import arange, fix

        nb_block_max = self.file_header.block_info[&#39;nb_block&#39;]  # total number of block in the file
        freq_res = self.file_header.freq_res  # frequency of block writing

        bts = self.file_header.block_info[&#39;time_size&#39;]
        bts2 = int(bts / 2)
        bts4 = int(bts / 4)
        dT = self.data_header[&#39;dt&#39;]
        origin_time = self.data_header[&#39;otime&#39;]

        # origin time of the file is the first sample read by febus (they skip one fourth of the first block)
        offset = bts4 * dT
        #offset_rule = offset
        # origin time of the file is the first sample of the file (this solution according to Gaëtan)
        offset_rule = 0.

        if skip:
            # !!!! if skip  = 2, one can read only an ODD number of blocks
            step_block = 2
            if nb_block_max % 2 == 0:
                nb_block_max = nb_block_max - 1  # The last EVEN block cannot be read
        else:
            # !!!! if skip  = 1, one can read any number of block
            step_block = 1
        #
        # define the read &lt;for&gt; loop indices: first_block, last_block
        #  for i, block in enumerate(range(first_block, last_block, step_block)):
        #
        if not trange:
            if block:
                first_block = block[0]
                last_block = min(block[1] + 1, nb_block_max)
                nb_block = last_block - first_block
            else:
                first_block = 0  # First block index for temporal acquisition
                nb_block = nb_block_max
                last_block = nb_block  # last block index in the reading loop, ie, never reached

            # for skip=2, read one block over 2, we scan an ODD number of block
            # start time is the beginning of the first block
            # !!!!! RECALL than nb_block IS NOT the number of blocks read, but the number of block scanned on the disk
            if skip:
                if nb_block % 2 == 0:
                    nb_block = max(nb_block + 1, nb_block_max)
                    last_block = first_block + nb_block - 1
                from_time = first_block * bts2 * dT
                # Total_time_size = number of time samples that we read in the time series
                total_time_size = (nb_block + 1) * bts2
                # total_time_size = nb_block * bts2 #ModifOC
                # time indices for 1st block, other blocks, last block
                time_indices = [[0, bts], [0, bts], [0, bts]]

            # for skip = 1, read every block, no restriction, but read only half of their size
            # start time is the first quarter of the first block because we don&#39;t want to manage
            # the 1st quarter of block (by laziness...)
            else:
                from_time = first_block * bts2 * dT + bts4 * dT
                total_time_size = nb_block * bts2
                # time indices for 1st block, other blocks, last block
                time_indices = [[bts4, 3 * bts4], [bts4, 3 * bts4], [bts4, 3 * bts4]]
        #
        # read only selected time range
        #
        else:
            from_time = trange[0]
            to_time = trange[1]

            if not skip:
                # check range that was given as argument
                min_time = bts4 * dT
                #min_time = 0.
                if from_time &lt; min_time:
                    from_time = min_time
                max_time = ((nb_block_max * bts2 + bts4) * dT)
                if to_time &gt; max_time:
                    to_time = (nb_block_max * bts2 + bts4) * dT
                    print(&#39;Warning: trange max is to high, set to:&#39;, str(to_time))

                # first_block = int(np.fix(from_time * freq_res))  # index of block containing the start time
                # last_block  = int(np.fix(to_time * freq_res)) + 1  # index of block containing the ending time + 1
                ##first_block = int(fix(from_time * freq_res)) - 1  # index of block containing the start time
                ##last_block = int(fix(to_time * freq_res))  # index of block containing the ending time + 1
                first_block = int(fix((from_time-offset) * freq_res))
                last_block  = int(fix((to_time-offset) * freq_res)) + 1
                if last_block &gt; nb_block_max:
                    last_block = nb_block_max
                nb_block = last_block - first_block

                # round from_time to the start time of the first block that is read
                # time indices for 1st block, other blocks, last block
                # For future use: if we decide not to round to block limits

                if not align_on_block:
                    dt_1 = from_time - (first_block * bts2 + bts4) * dT
                    i_1 = int(dt_1 / dT)
                    dt_last = to_time - ((last_block - 1) * bts2 + bts4) * dT
                    i_last = int(dt_last / dT)
                    if nb_block &gt;1:
                        time_indices = [[bts4 + i_1, 3 * bts4], [bts4, 3 * bts4], [bts4, i_last + bts4]]
                    else:
                        time_indices = [[bts4 + i_1, i_last + bts4], [bts4 + i_1, i_last + bts4], [bts4 + i_1, i_last + bts4]]
                    total_time_size = (nb_block * bts2) - i_1 - (bts2 - i_last)
                else:
                    time_indices = [[bts4, 3 * bts4], [bts4, 3 * bts4], [bts4, 3 * bts4]]
                    from_time = (first_block * bts2 + bts4) * dT
                    # Total_time_size = number of time samples in the time series
                    total_time_size = nb_block * bts2



            else:  # skip = True
                if from_time &lt; 0:
                    from_time = 0
                max_time = ((nb_block_max + 1) * bts2 * dT)
                if to_time &gt; max_time:
                    to_time = max_time

                # first_block = int(np.fix(from_time * freq_res))  # index of block containing the start time
                # last_block  = int(np.fix(to_time * freq_res)) + 1  # index of block containing the ending time
                ##first_block = int(fix(from_time * freq_res)) - 1 # index of block containing the start time
                ##last_block = int(fix(to_time * freq_res))  # index of block containing the ending time + 1
                first_block = int(fix((from_time) * freq_res / 2.))*2
                last_block  = int(fix((to_time) * freq_res / 2.))*2 + 1

                nb_block = last_block - first_block
                if nb_block % 2 == 0:  # Always read an ODD number of block
                    last_block += 1
                    nb_block += 1
                if last_block &gt; nb_block_max:
                    last_block = nb_block_max

                # round from_time to the start time of the first block that is read
                # For future use: if we decide not to round to block limits
                if not align_on_block:
                    # starting time in the first block of the first point
                    dt_1 = from_time - first_block * bts2 * dT
                    i_1 = int(dt_1 / dT)
                    # ending time in the last block of the first point
                    dt_last = to_time - (last_block - 1) * bts2 * dT
                    i_last = int(dt_last / dT)
                    if nb_block &gt; 1:
                        time_indices = [[i_1, bts], [0, bts], [0, i_last]]
                    else:
                        time_indices = [[i_1, i_last], [i_1, i_last], [i_1, i_last]]
                    total_time_size = (nb_block + 1) * bts2 - i_1 - (bts - i_last)
                else:
                    time_indices = [[0, bts], [0, bts], [0, bts]]
                    from_time = first_block * bts2 * dT
                    # Total_time_size = number of time samples in the time series
                    total_time_size = (nb_block + 1) * bts2

        # Create the time vector that contains samples datation
        # decimation can only be performed when reading entire blocks
        # The calling process must ensure that the block size is a multiplier of decimation factor
        # case no decimation
        if tdecim is None or tdecim == 1:
            time_vector_out = arange(0, total_time_size) * dT + from_time #+ origin_time
        # case no time range and time decimation
        elif not trange:
            time_vector_out = arange(0, total_time_size, tdecim) * dT + from_time #+ origin_time
        # case
        else:
            print(&#39;Time decimation is only valid when reading complete file or a block list&#39;)
            time_vector_out = arange(0, total_time_size) * dT + from_time #+ origin_time

        return first_block, last_block, step_block, time_vector_out, time_indices

    #
    # ====================================    _GET_SPACE_BOUND()  =======================================
    #
    def _get_space_bounds(self, drange=None, ddecim=None):
        &#39;&#39;&#39;
        A1File._get_space_bounds(drange, ddecim)

        :param drange: extract positions from from_to_position[0] to from_to_position[1], if not used set to None
        :param ddecim: space decimation step, if not used set to 1

        :return: distance_fiber_out, distance_indices, distance_fiber_in
                 distance_vector selected, array of distance indices in the input distance_vector
        &#39;&#39;&#39;
        from numpy import linspace, nanargmin

        ZI_start = self.data_header[&#39;ospace&#39;]
        dX = self.data_header[&#39;dx&#39;]
        distance_fiber_in = linspace(0, self.data_header[&#39;nspace&#39;] - 1, self.data_header[&#39;nspace&#39;]) * dX + ZI_start
        #ZI_end = distance_fiber_in[-1]

        # extract everything
        if not drange:
            first_point = 0  # index for 1st point
            last_point = self.data_header[&#39;nspace&#39;] - 1  # index for last point

        # extract a selected part
        else:
            # check range given as argument
            from_position = drange[0]
            to_position = drange[1]
            if from_position &lt; distance_fiber_in[0]:
                from_position = distance_fiber_in[0]
            if to_position &gt; distance_fiber_in[-1]:
                to_position = distance_fiber_in[-1]
                print(&#39;Warning: drange max is too high, set to &#39;, str(to_position))

            # set indices
            first_point = int(nanargmin(abs(distance_fiber_in- from_position)))
            last_point  = int(nanargmin(abs(distance_fiber_in- to_position)))

        # distance_length = Total_space_size
        # distance_start = First_point
        # distance_end = distance_start + distance_length
        distance_fiber_out = distance_fiber_in[
                             first_point:last_point + 1:ddecim]  # add 1 because last index is excluded
        distance_indices = range(first_point, last_point + 1, ddecim)  # add 1 because last index is excluded

        return distance_fiber_out, distance_indices, distance_fiber_in

    #
    # ====================================   SET_OTIME_FROM_FILENAME()  =======================================
    #
    def set_otime_from_filename(self, offset=0., prefix=None):
        &#34;&#34;&#34;
        ##Description
        Set data header origin time from the filename assuming Febus convention on the filename
        ex: SR_2021-08-26_14-32-39_UTC.h5.
        This call affect the origin time to file header and is propagated to all subsequent A1File.read() call
        This does not affect the values of the &lt;time&gt; vector which always refer to the origin (ie starting) time
        ##Input
            offset = a time offset to add/substract from the filename information
            prefix = a prefix ending by &#34;_&#34; in case the filename do not follow Febus convention (SR_, RAW_, S_, ...)
        &#34;&#34;&#34;
        from datetime import timezone, datetime
        from ._a1das_exception import WrongValueError

        name = self.file_header.filename
        # expected to be of the form SR_2021-08-26_14-32-39_UTC.h5
        if prefix is None:
            start = name.find(&#34;_&#34;)
            ofs = 1
        else:
            start = name.find(prefix)
            ofs = len(prefix)

        if start == -1:
            raise WrongValueError(&#39;could not set origin time from filename, check filename and/or prefix&#39;)
            return
        end = name.find(&#34;_UTC&#34;)
        s = name[start+ofs:end]
        # convert from string
        try:
            d = datetime.strptime(s, &#34;%Y-%m-%d_%H-%M-%S&#34;)
        except:
            raise ValueError(&#39;wrong date-time format, check file prefix&#39;)

        # convert to UTC
        dd = datetime(d.year, d.month, d.day, d.hour, d.minute, d.second, tzinfo=timezone.utc)
        # convert to Posix
        self.data_header.set_item(otime=dd.timestamp()+offset)

    def time(self):
        &#34;&#34;&#34;
        ## Description
        Return the time vector defined in the A1File data_header, i.e. same as f[&#39;time&#39;]
        &#34;&#34;&#34;
        return self.data_header[&#39;time&#39;]

    def dist(self):
        &#34;&#34;&#34;
        ## Description
        Return the distance vector defined in the A1File data_header, i.e. same as f[&#39;dist&#39;]
        &#34;&#34;&#34;
        return self.data_header[&#39;dist&#39;]</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="a1das.core.A1File.close"><code class="name flex">
<span>def <span class="ident">close</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Close a das file or socket stream</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close(self):
    &#34;&#34;&#34;
    Close a das file or socket stream

    &#34;&#34;&#34;
    from ._core_febus_file import close_das_file
    from ._core_socket import close_das_socket

    # On lit depuis un fichier
    if self.file_header:
        close_das_file(self.file_header)
        self.file_header = None

    # On lit depuis un socket
    elif self.socket_header:
        close_das_socket(self.socket_header)
        self.socket_header = None</code></pre>
</details>
</dd>
<dt id="a1das.core.A1File.dist"><code class="name flex">
<span>def <span class="ident">dist</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Return the distance vector defined in the A1File data_header, i.e. same as f['dist']</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dist(self):
    &#34;&#34;&#34;
    ## Description
    Return the distance vector defined in the A1File data_header, i.e. same as f[&#39;dist&#39;]
    &#34;&#34;&#34;
    return self.data_header[&#39;dist&#39;]</code></pre>
</details>
</dd>
<dt id="a1das.core.A1File.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, block=None, trange=None, drange=None, ddecim=1, skip=True, verbose=0, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Read data from a Febus/reducted file or a socket directly connected to Febus DAS
in memory and return a <code><a title="a1das.core.A1Section" href="#a1das.core.A1Section">A1Section</a></code> class instance.</p>
<p>All data are read unless one of the three options is set: block, trange, drange.
block is exclusive with trange,drange and return data aligned on block limits</p>
<p>Data are read as float32 and are converted by default as float64 unless specified</p>
<h2 id="input">Input:</h2>
<pre><code>block = (list), block=[start, end, step]. Read full block of data, from start to end by step.
    [0,0,?] read all blocks
    [] read one block
    default = None
trange = (list), in sec, trange=[start_time, end_time], select time from start_time to end_time
    default = None
drange = (list), in meter, drange=[start_position, end_position], select distance from start_position
    to end_position
    default = None
ddecim = decimation along spatial dimension, (must be a divider of chunck/block size)

skip = read all blocks/chunck of data (False) or one over 2 (True)
    blocks contains redundant data, skip=True is faster but may yield some errors on block limits

verbose = verbosity level

**kwargs= any optionnal supplementary arguments, see below
</code></pre>
<h2 id="return">Return:</h2>
<p>A <code><a title="a1das.core.A1Section" href="#a1das.core.A1Section">A1Section</a></code> class instance</p>
<h2 id="usage-example">Usage example</h2>
<pre><code>&gt;&gt;&gt; import a1das
&gt;&gt;&gt; f = a1das.open("my_filename")
&gt;&gt;&gt; a1 = f.read(trange=(0.,1800.),drange=(100., 900.),skip=False)
</code></pre>
<h2 id="optionnal-arguments">optionnal arguments</h2>
<pre><code>float_type = 'float_32' or 'float_64' for febus file only
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, block=None, trange=None, drange=None, ddecim=1, skip=True, verbose=0, **kwargs):
    &#34;&#34;&#34;
    ## Description
    Read data from a Febus/reducted file or a socket directly connected to Febus DAS
    in memory and return a `A1Section` class instance.

    All data are read unless one of the three options is set: block, trange, drange.
    block is exclusive with trange,drange and return data aligned on block limits

    Data are read as float32 and are converted by default as float64 unless specified

    ## Input:
        block = (list), block=[start, end, step]. Read full block of data, from start to end by step.
            [0,0,?] read all blocks
            [] read one block
            default = None
        trange = (list), in sec, trange=[start_time, end_time], select time from start_time to end_time
            default = None
        drange = (list), in meter, drange=[start_position, end_position], select distance from start_position
            to end_position
            default = None
        ddecim = decimation along spatial dimension, (must be a divider of chunck/block size)

        skip = read all blocks/chunck of data (False) or one over 2 (True)
            blocks contains redundant data, skip=True is faster but may yield some errors on block limits

        verbose = verbosity level

        **kwargs= any optionnal supplementary arguments, see below

    ## Return:
    A `A1Section` class instance

    ## Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f = a1das.open(&#34;my_filename&#34;)
        &gt;&gt;&gt; a1 = f.read(trange=(0.,1800.),drange=(100., 900.),skip=False)

    ## optionnal arguments
        float_type = &#39;float_32&#39; or &#39;float_64&#39; for febus file only
    &#34;&#34;&#34;

    from ._core_febus_file import read_febus_file
    from ._core_reducted_file import read_reducted_file
    from ._core_socket import read_das_socket

    # read from a file (febus or reducted)
    if self.file_header is not None:
        if self.file_header.type == &#39;febus&#39;:
            data_header, data = read_febus_file(self, block, trange, drange, ddecim, skip, verbose=verbose,**kwargs)

        elif self.file_header.type == &#39;reducted&#39;:
            data_header, data = read_reducted_file(self, trange=trange, drange=drange, verbose=verbose,**kwargs)

    # read from a socket
    elif self.socket_header is not None:
        data_header, data = read_das_socket(self, block, drange=drange, ddecim=ddecim,**kwargs)

    else:
        data_header = data = None

    # create A1DSection class instance
    if self.file_header is not None:
        data_header.set_item(filename=self.file_header.filename)

    return A1Section(data_header, data)</code></pre>
</details>
</dd>
<dt id="a1das.core.A1File.set_item"><code class="name flex">
<span>def <span class="ident">set_item</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Update/create a matadata entry in the data_header class dictionnary attached to the A1File</p>
<h2 id="input">Input</h2>
<pre><code>**kwargs = arbitrary list of key_word = value
</code></pre>
<h2 id="usage-example">Usage example</h2>
<pre><code>&gt;&gt;&gt; import a1das
&gt;&gt;&gt; f=a1das.open(filename)
&gt;&gt;&gt; f.set_item(dog_name='medor',dog_food='candies',dog_age=7)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_item(self, **kwargs):
    &#34;&#34;&#34;
    ##Description
    Update/create a matadata entry in the data_header class dictionnary attached to the A1File

    ##Input
        **kwargs = arbitrary list of key_word = value
    ##Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f=a1das.open(filename)
        &gt;&gt;&gt; f.set_item(dog_name=&#39;medor&#39;,dog_food=&#39;candies&#39;,dog_age=7)

    &#34;&#34;&#34;
    self.data_header.set_item(kwargs)</code></pre>
</details>
</dd>
<dt id="a1das.core.A1File.set_otime_from_filename"><code class="name flex">
<span>def <span class="ident">set_otime_from_filename</span></span>(<span>self, offset=0.0, prefix=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Set data header origin time from the filename assuming Febus convention on the filename
ex: SR_2021-08-26_14-32-39_UTC.h5.
This call affect the origin time to file header and is propagated to all subsequent A1File.read() call
This does not affect the values of the <time> vector which always refer to the origin (ie starting) time</p>
<h2 id="input">Input</h2>
<pre><code>offset = a time offset to add/substract from the filename information
prefix = a prefix ending by "_" in case the filename do not follow Febus convention (SR_, RAW_, S_, ...)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_otime_from_filename(self, offset=0., prefix=None):
    &#34;&#34;&#34;
    ##Description
    Set data header origin time from the filename assuming Febus convention on the filename
    ex: SR_2021-08-26_14-32-39_UTC.h5.
    This call affect the origin time to file header and is propagated to all subsequent A1File.read() call
    This does not affect the values of the &lt;time&gt; vector which always refer to the origin (ie starting) time
    ##Input
        offset = a time offset to add/substract from the filename information
        prefix = a prefix ending by &#34;_&#34; in case the filename do not follow Febus convention (SR_, RAW_, S_, ...)
    &#34;&#34;&#34;
    from datetime import timezone, datetime
    from ._a1das_exception import WrongValueError

    name = self.file_header.filename
    # expected to be of the form SR_2021-08-26_14-32-39_UTC.h5
    if prefix is None:
        start = name.find(&#34;_&#34;)
        ofs = 1
    else:
        start = name.find(prefix)
        ofs = len(prefix)

    if start == -1:
        raise WrongValueError(&#39;could not set origin time from filename, check filename and/or prefix&#39;)
        return
    end = name.find(&#34;_UTC&#34;)
    s = name[start+ofs:end]
    # convert from string
    try:
        d = datetime.strptime(s, &#34;%Y-%m-%d_%H-%M-%S&#34;)
    except:
        raise ValueError(&#39;wrong date-time format, check file prefix&#39;)

    # convert to UTC
    dd = datetime(d.year, d.month, d.day, d.hour, d.minute, d.second, tzinfo=timezone.utc)
    # convert to Posix
    self.data_header.set_item(otime=dd.timestamp()+offset)</code></pre>
</details>
</dd>
<dt id="a1das.core.A1File.time"><code class="name flex">
<span>def <span class="ident">time</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Return the time vector defined in the A1File data_header, i.e. same as f['time']</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def time(self):
    &#34;&#34;&#34;
    ## Description
    Return the time vector defined in the A1File data_header, i.e. same as f[&#39;time&#39;]
    &#34;&#34;&#34;
    return self.data_header[&#39;time&#39;]</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="a1das.core.A1Section"><code class="flex name class">
<span>class <span class="ident">A1Section</span></span>
<span>(</span><span>dhd=None, data=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>A1Section class contains das data and metadata read from file or TCP stream</p>
<h2 id="class-content">Class content</h2>
<pre><code>A1Section.data:         2D float array (ndarray of shape [ntime x nspace] or [nspace x ntime])
A1Section.data_header   metadata       (_A1DataHeader class instance)
</code></pre>
<h2 id="readingsetting-data_header-metadata">Reading/setting data_header metadata</h2>
<p>Read directly as a dictionnary from a1_section ex: a1['dt'] or through data_header ex: a1.data_header['dt']</p>
<p>Set by the set_item method() ex: a1.set_item(dt=0.1) or through data_header ex: a1.data_header.set_item(dt=0.1)</p>
<h2 id="usage-example">Usage example</h2>
<pre><code>&gt;&gt;&gt;import a1das
&gt;&gt;&gt;f=a1das.open(filename)   # open file
&gt;&gt;&gt;a1 = f.read()            # read section
&gt;&gt;&gt;a1                       # print header values
&gt;&gt;&gt;time_step=a1['dt']       # get time step
&gt;&gt;&gt;a1.set_item(dt=0.1)      # set time step
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class A1Section:
    &#34;&#34;&#34;
    ## Description
    A1Section class contains das data and metadata read from file or TCP stream

    ## Class content

        A1Section.data:         2D float array (ndarray of shape [ntime x nspace] or [nspace x ntime])
        A1Section.data_header   metadata       (_A1DataHeader class instance)


    ## Reading/setting data_header metadata
    Read directly as a dictionnary from a1_section ex: a1[&#39;dt&#39;] or through data_header ex: a1.data_header[&#39;dt&#39;]

    Set by the set_item method() ex: a1.set_item(dt=0.1) or through data_header ex: a1.data_header.set_item(dt=0.1)
    ##Usage example
        &gt;&gt;&gt;import a1das
        &gt;&gt;&gt;f=a1das.open(filename)   # open file
        &gt;&gt;&gt;a1 = f.read()            # read section
        &gt;&gt;&gt;a1                       # print header values
        &gt;&gt;&gt;time_step=a1[&#39;dt&#39;]       # get time step
        &gt;&gt;&gt;a1.set_item(dt=0.1)      # set time step

    &#34;&#34;&#34;
    def __init__(self, dhd=None, data=None):
        self.data_header = dhd    # dictionnary of header values
        self.data = data          # numpy 2D ndarray.
                                  # If data_header[&#39;axis&#39;] = &#39;time_x_space&#39; first dimension is time
                                  # If data_header[&#39;axis&#39;] = &#39;space_x_time&#39; first dimension is space

    def time(self):
        &#34;&#34;&#34;
        ## Description
        Return the time vector defined in the &lt;A1Section&gt; data_header, i.e. shortcut for a1.data_header[&#39;time&#39;]
        &#34;&#34;&#34;
        return self.data_header[&#39;time&#39;]

    def dist(self):
        &#34;&#34;&#34;
        ## Description
        Return the distance vector defined in the &lt;A1Section&gt; data_header, i.e. shortcut for a1.data_header[&#39;dist&#39;]
        &#34;&#34;&#34;
        return self.data_header[&#39;dist&#39;]

    def otime(self):
        &#34;&#34;&#34;
        ##Description
        Return the UTC origin (or start) time of the section
        in two formats: Posix time and string

        ##Return
        posix_otime, string_otime
        &#34;&#34;&#34;
        from datetime import datetime, timezone
        time = self[&#39;time&#39;]   # could read otime too
        otime=time[0]

        return otime, datetime.fromtimestamp(otime, tz=timezone.utc).strftime(&#39;%Y:%M:%d-%H:%M:%S.%f&#39;)


    def __str__(self):
        from io import StringIO
        s = StringIO()

        s.write(&#39;\n&lt;A1Section&gt;:&#39;)
        s.write(&#39;\n--------------&#39;)
        s.write(&#39;\ndata: \nndarray data[&#39;+str(self.data_header[&#39;ntime&#39;])+&#39;x&#39;+str(self.data_header[&#39;nspace&#39;])+&#39;]\n&#39;)
        # print file_header part
        s.write(&#39;\ndata_header: &#39;)
        s.write(self.data_header.__str__())

        return s.getvalue()

    def __repr__(self):
        return self.__str__()

    def set_item(self, **kwargs):
        &#34;&#34;&#34;
        ##Description
        Update/create a matadata entry in the data_header class dictionnary attached to A1Section

        ##Input
            **kwargs = arbitrary list of key_word = value
        ##Usage example
            &gt;&gt;&gt; import a1das
            &gt;&gt;&gt; f=a1das.open(filename)
            &gt;&gt;&gt; a=f.read()
            &gt;&gt;&gt; a.set_item(cat_name=&#39;medor&#39;,cat_food=&#39;candies&#39;,cat_age=7)

        &#34;&#34;&#34;
        self.data_header.set_item(kwargs)
        
    def __getitem__(self, item):
        &#34;&#34;&#34;
        overload [] operator for the A1Section class
        &#34;&#34;&#34;
        try:
            return self.data_header._header[item]
        except:
            return None
    #
    # ====================================   SET_OTIME_FROM_FILENAME()  =======================================
    #
    def set_otime_from_filename(self, offset=0., prefix=None):
        &#34;&#34;&#34;
        ##Description
        Set data header origin time from the filename assuming Febus convention on the filename
        ex: SR_2021-08-26_14-32-39_UTC.h5.
        This call affect the origin time to file header and is propagated to all subsequent A1File.read() call
        This does not affect the values of the &lt;time&gt; vector which always refer to the origin (ie starting) time

        ##Input
            offset = a time offset to add/substract from the filename information
            prefix = a prefix ending by &#34;_&#34; in case the filename do not follow Febus convention (SR_, RAW_, S_, ...)
        &#34;&#34;&#34;
        from datetime import timezone, datetime
        from ._a1das_exception import WrongValueError

        if &#39;filename&#39; in self.data_header._header.keys():
            name = self.data_header[&#39;filename&#39;]
            # expected to be of the form SR_2021-08-26_14-32-39_UTC.h5
            if prefix is None:
                start = name.find(&#34;_&#34;)
                ofs = 1
            else:
                start = name.find(prefix)
                ofs = len(prefix)

            if start == -1:
                raise WrongValueError(&#39;could not set origin time from filename, check filename and/or prefix&#39;)
                return
            end = name.find(&#34;_UTC&#34;)
            s = name[start+ofs:end]
            # convert from string
            try:
                d = datetime.strptime(s, &#34;%Y-%m-%d_%H-%M-%S&#34;)
            except:
                raise ValueError(&#39;wrong date-time format, check file prefix&#39;)

            # convert to UTC
            dd = datetime(d.year,d.month,d.day,d.hour,d.minute,d.second, tzinfo=timezone.utc)
            # convert to Posix
            self.data_header.set_item(otime=dd.timestamp()+offset)
        else:
            raise WrongValueError(&#39;&lt;filename&gt; is not defined in data header&#39;)

    #
    # ====================================   OBSPY_STREAM()  =======================================
    #
    def obspy_stream(self, drange=None, station_name=None):
        &#34;&#34;&#34;
        ##Description
        Return an obspy stream from a DAS section with optional spatial range drange

        ##Input
            drange: = (dmin, dmax) list or tuple with minimal and maximal distance in meter
        ##Return
            An obspy stream
        &#34;&#34;&#34;
        from obspy.core import Stream, Trace, UTCDateTime
        from ._a1das_exception import WrongValueError

        st = Stream()
        if drange is None:
            s0=0
            s1=self[&#39;nspace&#39;]
        else:
            s = self.index(drange)
            s0 = s[0]
            s1 = s[1]+1

        dist = self[&#39;dist&#39;]
        time = self[&#39;time&#39;]
        if station_name is None:
            station_name = &#39;DAS&#39;
        for i in range(s0, s1):
            header = {&#39;npts&#39;: self.data_header[&#39;ntime&#39;],
                      &#39;station&#39;: station_name,
                      &#39;starttime&#39;: UTCDateTime(self.data_header[&#39;otime&#39;]+time[0]),
                      #&#39;sampling_rate&#39;: 1./float64(self.data_header[&#39;dt&#39;]),
                      &#39;location&#39;: str(int(dist[i]))+&#39;m&#39;,
                      &#39;channel&#39;: &#39;S&#39;,
                      &#39;delta&#39; : self.data_header[&#39;dt&#39;]
                      }
            if self.data_header[&#39;data_axis&#39;] == &#39;time_x_space&#39;:
                st.append(Trace(data=self.data[:,i], header=header))
            elif self.data_header[&#39;data_axis&#39;] == &#39;space_x_time&#39;:
                st.append(Trace(data=self.data[i,:], header=header))
            else:
                raise WrongValueError(&#39;&lt;data_axis&gt; header field is neither &lt;time_x_space&gt; nor &lt;space_x_time&gt;&#39;)
        return st

    # ====================================   INDEX()  =======================================
    #
    def index(self, drange=None, trange=None):
        &#34;&#34;&#34;
        ## Description
        Return the index or list of indices that correspond(s) to the list of distance(resp. time) range
        in the &#39;distance&#39; vector (resp. time vector)

        ## Input
        !!!!! Only one of trange or drange can be given

        drange = [unique_dist]; [dist_min, dist_max]; [d1, d2, ... dN]  (default = None)

        trange = [unique_time]; [time_min, time_max]; [t1, t2, ... tN]  (default = None)

        ## Return
        A list of indices that matches the given range in the A1Section.data_header[&#39;dist&#39;] or
        A1Section.data_header[&#39;time&#39;] vectors

        ## Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f=open(&#39;filename&#39;)
        &gt;&gt;&gt; a=f.read()
        &gt;&gt;&gt; dlist1 = a.index(drange=[50.])          # single index at distance 50 m
        &gt;&gt;&gt; dlist1 = a.index(50.)                   # single index at distance 50 m
        &gt;&gt;&gt; dlist2 = a.index(drange=[50., 60.])     # 2 indices at 50m and 60m
        &gt;&gt;&gt; dlist3 = a.index(drange=[[dist] for dist in np.arange(50,60.,1.)]) # all indices for distance 50&lt; ..&lt;60 every 1m
        &gt;&gt;&gt; tlist = a.index(trange=[10.,11.])       # time indices for time between 10. and 20s after 1st sample
        &#34;&#34;&#34;
        from numpy import nanargmin, abs, ndarray
        from ._a1das_exception import DataTypeError, WrongValueError

        if drange is not None and trange is not None:
            raise WrongValueError(&#39;cannot define trange AND drange, select one of two&#39;)

        if drange is None and trange is None:
            raise WrongValueError(&#39;Please define one of drange(distance range) or trange (time range)&#39;)

        if drange is not None:
            dtrange=drange
            vec = self.data_header[&#39;dist&#39;]
        else:
            dtrange=trange
            vec = self.data_header[&#39;time&#39;]

        if isinstance(dtrange, ndarray):
            raise DataTypeError(&#39;range must be a list or tuple&#39;)

        if isinstance(dtrange,float):
            dtrange=[dtrange]

        if dtrange is None:
            return [0, -1]

        d1 = nanargmin(abs(vec - dtrange[0]))
        indx = [d1]
        if len(dtrange) == 1:
            indx.append(d1+1)
        else:
            for i in range(1,len(dtrange)):
                indx.append(nanargmin(abs(vec-dtrange[i])))
        return indx
    #
    # ====================================   PLOT()  =======================================
    #
    def plot(self, fig=None, clip=100, splot=(1, 1, 1), title=&#39;&#39;, max=100, amax=None, variable_area=False, drange=None, trange=None, redraw=None):
        &#34;&#34;&#34;
        ##Description
        Produce a vector plot of the das section, optionnaly with variable area
        ##Input
            fig= figure handle (default None)
            clip= (int) clip amplitude at clip% of the max amplitude (default 100%)
            splot= (tupple) plot as a subplot (default subplot(1,1,1))
            title= (str) figure title (default None)
            max= (int) maximum number of traces on the plot (default 100)
            amax= maximum amplitude for clipping if not using clip percentage (default None)
            variable_area= (bool) plot with variable_are (half wiggle is filled in black) (default False)
            drange= (tupple) distance range [dmin, dmax]
            trange= (tupple) time range [tmin, tmax]
            redraw = {lines} redraw lines of a precedent figure  or None for new plot, requires fig argument

        ##Return
            figure_handle, curve_list

        ##Usage example
            &gt;&gt;&gt;import a1das
            &gt;&gt;&gt;f=a1das.open(filename)
            &gt;&gt;&gt;a1=f.read()
            &gt;&gt;&gt;a1.plot(clip=50,variable_area=True)
        &#34;&#34;&#34;
        from a1das._plot import plot
        from ._a1das_exception import ReadDataError

        if self.data is None:
            raise ReadDataError(&#39;Hum Hum, read data before plotting ...&#39;)

        fig, redraw = plot(self,fig, clip, splot, title, max, amax, variable_area, drange, trange, redraw)

        return fig, redraw
    #
    # ====================================   RPLOT()  =======================================
    #
    def rplot(self, fig=None, cmap=&#39;RdBu&#39;, vrange=None, splot=(1, 1, 1), title=&#39;&#39;, drange=None, trange=None):
        &#34;&#34;&#34;
        ##Description
        Produce a raster plot of the das section
        ##Input
            fig= figure handle (default None)
            cmap= colormap (default=RdBu)
            vrange= trace amplitude range (default None)
            splot= plot as a subplot (default subplot(1,1,1))
            title= figure title (default None)
            drange= distance range
            trange= time range

        ## Return
            figure_handle, axes_handle

        ##Usage example
            &gt;&gt;&gt;import a1das
            &gt;&gt;&gt;f=a1das.open(filename)
            &gt;&gt;&gt;a1=f.read()
            &gt;&gt;&gt;a1.rplot()
        &#34;&#34;&#34;
        from a1das._plot import rplot
        from ._a1das_exception import ReadDataError

        if self.data is None:
            raise ReadDataError(&#39;Hum Hum, read data before plotting ...&#39;)

        fig, ax = rplot(self,fig, cmap, vrange, splot, title, drange, trange)

        return fig, ax

    def save(self,filename):
        &#34;&#34;&#34;
        ## Description
        a.save(filename)

        Save a `A1Section` that has been read, extracted or converted from stream or files into the reducted file format.

        ## Input
        filename= a name for the hdf5 file that contains the reducted file

        ## Usage example
            &gt;&gt;&gt; import a1das
            &gt;&gt;&gt; f = a1das.open(&#39;my_filename&#39;, format=&#39;febus&#39;)
            &gt;&gt;&gt; a = f.read(trange=(tmin,tmax), drange=(dmin,dmax), skip=False) # read and extract a subportion of the original file
            &gt;&gt;&gt; a.save(&#39;new_section&#39;) # &#39;a&#39; can be read later using the same a1das.open() and f.read() functions
            &gt;&gt;&gt; f.close()

        &#34;&#34;&#34;
        from ._core_reducted_file import _save_reducted_file
        _save_reducted_file(self,filename)

    def concat(self, b):
        &#34;&#34;&#34;
        ## Description
            a.concat(b): Concatenate section b behind section a along the fast axis
            if a and b are ordered as [space x time], fast axis is time and on obtain a new section [ space x 2*time]
            if a and b are ordered as [time x space], not implemented

        ## Return
            a new section
        &#34;&#34;&#34;
        import numpy as np
        from ._a1das_exception import DataTypeError

        if self[&#39;data_axis&#39;] != &#39;time_x_space&#39; or b[&#39;data_axis&#39;] != &#39;time_x_space&#39;:
            raise DataTypeError(&#39;section must be ordered with data as time x space&#39;)

        time_a = self[&#39;time&#39;]
        time_b = b[&#39;time&#39;]

        nspace_a = self[&#39;nspace&#39;]
        nspace_b = b[&#39;nspace&#39;]
        if nspace_a != nspace_b:
            raise DataTypeError(&#39;concat: different spatial spacing&#39;)

        dta = self[&#39;dt&#39;]
        dtb = b[&#39;dt&#39;]
        if dta != dtb:
            raise DataTypeError(&#39;concat failed, different sampling rate&#39;)


        # Create new section
        data_header = self.data_header.copy()
        data_header.set_item(ntime=self[&#39;ntime&#39;]+b[&#39;ntime&#39;])
        data_header.set_item(time=np.concatenate((time_a,time_b)))
        newdata = np.vstack((self.data, b.data))

        return A1Section(data_header, newdata)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="a1das.core.A1Section.concat"><code class="name flex">
<span>def <span class="ident">concat</span></span>(<span>self, b)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<pre><code>a.concat(b): Concatenate section b behind section a along the fast axis
if a and b are ordered as [space x time], fast axis is time and on obtain a new section [ space x 2*time]
if a and b are ordered as [time x space], not implemented
</code></pre>
<h2 id="return">Return</h2>
<pre><code>a new section
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def concat(self, b):
    &#34;&#34;&#34;
    ## Description
        a.concat(b): Concatenate section b behind section a along the fast axis
        if a and b are ordered as [space x time], fast axis is time and on obtain a new section [ space x 2*time]
        if a and b are ordered as [time x space], not implemented

    ## Return
        a new section
    &#34;&#34;&#34;
    import numpy as np
    from ._a1das_exception import DataTypeError

    if self[&#39;data_axis&#39;] != &#39;time_x_space&#39; or b[&#39;data_axis&#39;] != &#39;time_x_space&#39;:
        raise DataTypeError(&#39;section must be ordered with data as time x space&#39;)

    time_a = self[&#39;time&#39;]
    time_b = b[&#39;time&#39;]

    nspace_a = self[&#39;nspace&#39;]
    nspace_b = b[&#39;nspace&#39;]
    if nspace_a != nspace_b:
        raise DataTypeError(&#39;concat: different spatial spacing&#39;)

    dta = self[&#39;dt&#39;]
    dtb = b[&#39;dt&#39;]
    if dta != dtb:
        raise DataTypeError(&#39;concat failed, different sampling rate&#39;)


    # Create new section
    data_header = self.data_header.copy()
    data_header.set_item(ntime=self[&#39;ntime&#39;]+b[&#39;ntime&#39;])
    data_header.set_item(time=np.concatenate((time_a,time_b)))
    newdata = np.vstack((self.data, b.data))

    return A1Section(data_header, newdata)</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.dist"><code class="name flex">
<span>def <span class="ident">dist</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Return the distance vector defined in the <A1Section> data_header, i.e. shortcut for a1.data_header['dist']</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dist(self):
    &#34;&#34;&#34;
    ## Description
    Return the distance vector defined in the &lt;A1Section&gt; data_header, i.e. shortcut for a1.data_header[&#39;dist&#39;]
    &#34;&#34;&#34;
    return self.data_header[&#39;dist&#39;]</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.index"><code class="name flex">
<span>def <span class="ident">index</span></span>(<span>self, drange=None, trange=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Return the index or list of indices that correspond(s) to the list of distance(resp. time) range
in the 'distance' vector (resp. time vector)</p>
<h2 id="input">Input</h2>
<p>!!!!! Only one of trange or drange can be given</p>
<p>drange = [unique_dist]; [dist_min, dist_max]; [d1, d2, &hellip; dN]
(default = None)</p>
<p>trange = [unique_time]; [time_min, time_max]; [t1, t2, &hellip; tN]
(default = None)</p>
<h2 id="return">Return</h2>
<p>A list of indices that matches the given range in the A1Section.data_header['dist'] or
A1Section.data_header['time'] vectors</p>
<h2 id="usage-example">Usage example</h2>
<pre><code class="language-python-repl">&gt;&gt;&gt; import a1das
&gt;&gt;&gt; f=open('filename')
&gt;&gt;&gt; a=f.read()
&gt;&gt;&gt; dlist1 = a.index(drange=[50.])          # single index at distance 50 m
&gt;&gt;&gt; dlist1 = a.index(50.)                   # single index at distance 50 m
&gt;&gt;&gt; dlist2 = a.index(drange=[50., 60.])     # 2 indices at 50m and 60m
&gt;&gt;&gt; dlist3 = a.index(drange=[[dist] for dist in np.arange(50,60.,1.)]) # all indices for distance 50&lt; ..&lt;60 every 1m
&gt;&gt;&gt; tlist = a.index(trange=[10.,11.])       # time indices for time between 10. and 20s after 1st sample
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def index(self, drange=None, trange=None):
    &#34;&#34;&#34;
    ## Description
    Return the index or list of indices that correspond(s) to the list of distance(resp. time) range
    in the &#39;distance&#39; vector (resp. time vector)

    ## Input
    !!!!! Only one of trange or drange can be given

    drange = [unique_dist]; [dist_min, dist_max]; [d1, d2, ... dN]  (default = None)

    trange = [unique_time]; [time_min, time_max]; [t1, t2, ... tN]  (default = None)

    ## Return
    A list of indices that matches the given range in the A1Section.data_header[&#39;dist&#39;] or
    A1Section.data_header[&#39;time&#39;] vectors

    ## Usage example
    &gt;&gt;&gt; import a1das
    &gt;&gt;&gt; f=open(&#39;filename&#39;)
    &gt;&gt;&gt; a=f.read()
    &gt;&gt;&gt; dlist1 = a.index(drange=[50.])          # single index at distance 50 m
    &gt;&gt;&gt; dlist1 = a.index(50.)                   # single index at distance 50 m
    &gt;&gt;&gt; dlist2 = a.index(drange=[50., 60.])     # 2 indices at 50m and 60m
    &gt;&gt;&gt; dlist3 = a.index(drange=[[dist] for dist in np.arange(50,60.,1.)]) # all indices for distance 50&lt; ..&lt;60 every 1m
    &gt;&gt;&gt; tlist = a.index(trange=[10.,11.])       # time indices for time between 10. and 20s after 1st sample
    &#34;&#34;&#34;
    from numpy import nanargmin, abs, ndarray
    from ._a1das_exception import DataTypeError, WrongValueError

    if drange is not None and trange is not None:
        raise WrongValueError(&#39;cannot define trange AND drange, select one of two&#39;)

    if drange is None and trange is None:
        raise WrongValueError(&#39;Please define one of drange(distance range) or trange (time range)&#39;)

    if drange is not None:
        dtrange=drange
        vec = self.data_header[&#39;dist&#39;]
    else:
        dtrange=trange
        vec = self.data_header[&#39;time&#39;]

    if isinstance(dtrange, ndarray):
        raise DataTypeError(&#39;range must be a list or tuple&#39;)

    if isinstance(dtrange,float):
        dtrange=[dtrange]

    if dtrange is None:
        return [0, -1]

    d1 = nanargmin(abs(vec - dtrange[0]))
    indx = [d1]
    if len(dtrange) == 1:
        indx.append(d1+1)
    else:
        for i in range(1,len(dtrange)):
            indx.append(nanargmin(abs(vec-dtrange[i])))
    return indx</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.obspy_stream"><code class="name flex">
<span>def <span class="ident">obspy_stream</span></span>(<span>self, drange=None, station_name=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Return an obspy stream from a DAS section with optional spatial range drange</p>
<h2 id="input">Input</h2>
<pre><code>drange: = (dmin, dmax) list or tuple with minimal and maximal distance in meter
</code></pre>
<h2 id="return">Return</h2>
<pre><code>An obspy stream
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def obspy_stream(self, drange=None, station_name=None):
    &#34;&#34;&#34;
    ##Description
    Return an obspy stream from a DAS section with optional spatial range drange

    ##Input
        drange: = (dmin, dmax) list or tuple with minimal and maximal distance in meter
    ##Return
        An obspy stream
    &#34;&#34;&#34;
    from obspy.core import Stream, Trace, UTCDateTime
    from ._a1das_exception import WrongValueError

    st = Stream()
    if drange is None:
        s0=0
        s1=self[&#39;nspace&#39;]
    else:
        s = self.index(drange)
        s0 = s[0]
        s1 = s[1]+1

    dist = self[&#39;dist&#39;]
    time = self[&#39;time&#39;]
    if station_name is None:
        station_name = &#39;DAS&#39;
    for i in range(s0, s1):
        header = {&#39;npts&#39;: self.data_header[&#39;ntime&#39;],
                  &#39;station&#39;: station_name,
                  &#39;starttime&#39;: UTCDateTime(self.data_header[&#39;otime&#39;]+time[0]),
                  #&#39;sampling_rate&#39;: 1./float64(self.data_header[&#39;dt&#39;]),
                  &#39;location&#39;: str(int(dist[i]))+&#39;m&#39;,
                  &#39;channel&#39;: &#39;S&#39;,
                  &#39;delta&#39; : self.data_header[&#39;dt&#39;]
                  }
        if self.data_header[&#39;data_axis&#39;] == &#39;time_x_space&#39;:
            st.append(Trace(data=self.data[:,i], header=header))
        elif self.data_header[&#39;data_axis&#39;] == &#39;space_x_time&#39;:
            st.append(Trace(data=self.data[i,:], header=header))
        else:
            raise WrongValueError(&#39;&lt;data_axis&gt; header field is neither &lt;time_x_space&gt; nor &lt;space_x_time&gt;&#39;)
    return st</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.otime"><code class="name flex">
<span>def <span class="ident">otime</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Return the UTC origin (or start) time of the section
in two formats: Posix time and string</p>
<h2 id="return">Return</h2>
<p>posix_otime, string_otime</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def otime(self):
    &#34;&#34;&#34;
    ##Description
    Return the UTC origin (or start) time of the section
    in two formats: Posix time and string

    ##Return
    posix_otime, string_otime
    &#34;&#34;&#34;
    from datetime import datetime, timezone
    time = self[&#39;time&#39;]   # could read otime too
    otime=time[0]

    return otime, datetime.fromtimestamp(otime, tz=timezone.utc).strftime(&#39;%Y:%M:%d-%H:%M:%S.%f&#39;)</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, fig=None, clip=100, splot=(1, 1, 1), title='', max=100, amax=None, variable_area=False, drange=None, trange=None, redraw=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Produce a vector plot of the das section, optionnaly with variable area</p>
<h2 id="input">Input</h2>
<pre><code>fig= figure handle (default None)
clip= (int) clip amplitude at clip% of the max amplitude (default 100%)
splot= (tupple) plot as a subplot (default subplot(1,1,1))
title= (str) figure title (default None)
max= (int) maximum number of traces on the plot (default 100)
amax= maximum amplitude for clipping if not using clip percentage (default None)
variable_area= (bool) plot with variable_are (half wiggle is filled in black) (default False)
drange= (tupple) distance range [dmin, dmax]
trange= (tupple) time range [tmin, tmax]
redraw = {lines} redraw lines of a precedent figure  or None for new plot, requires fig argument
</code></pre>
<h2 id="return">Return</h2>
<pre><code>figure_handle, curve_list
</code></pre>
<h2 id="usage-example">Usage example</h2>
<pre><code>&gt;&gt;&gt;import a1das
&gt;&gt;&gt;f=a1das.open(filename)
&gt;&gt;&gt;a1=f.read()
&gt;&gt;&gt;a1.plot(clip=50,variable_area=True)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self, fig=None, clip=100, splot=(1, 1, 1), title=&#39;&#39;, max=100, amax=None, variable_area=False, drange=None, trange=None, redraw=None):
    &#34;&#34;&#34;
    ##Description
    Produce a vector plot of the das section, optionnaly with variable area
    ##Input
        fig= figure handle (default None)
        clip= (int) clip amplitude at clip% of the max amplitude (default 100%)
        splot= (tupple) plot as a subplot (default subplot(1,1,1))
        title= (str) figure title (default None)
        max= (int) maximum number of traces on the plot (default 100)
        amax= maximum amplitude for clipping if not using clip percentage (default None)
        variable_area= (bool) plot with variable_are (half wiggle is filled in black) (default False)
        drange= (tupple) distance range [dmin, dmax]
        trange= (tupple) time range [tmin, tmax]
        redraw = {lines} redraw lines of a precedent figure  or None for new plot, requires fig argument

    ##Return
        figure_handle, curve_list

    ##Usage example
        &gt;&gt;&gt;import a1das
        &gt;&gt;&gt;f=a1das.open(filename)
        &gt;&gt;&gt;a1=f.read()
        &gt;&gt;&gt;a1.plot(clip=50,variable_area=True)
    &#34;&#34;&#34;
    from a1das._plot import plot
    from ._a1das_exception import ReadDataError

    if self.data is None:
        raise ReadDataError(&#39;Hum Hum, read data before plotting ...&#39;)

    fig, redraw = plot(self,fig, clip, splot, title, max, amax, variable_area, drange, trange, redraw)

    return fig, redraw</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.rplot"><code class="name flex">
<span>def <span class="ident">rplot</span></span>(<span>self, fig=None, cmap='RdBu', vrange=None, splot=(1, 1, 1), title='', drange=None, trange=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Produce a raster plot of the das section</p>
<h2 id="input">Input</h2>
<pre><code>fig= figure handle (default None)
cmap= colormap (default=RdBu)
vrange= trace amplitude range (default None)
splot= plot as a subplot (default subplot(1,1,1))
title= figure title (default None)
drange= distance range
trange= time range
</code></pre>
<h2 id="return">Return</h2>
<pre><code>figure_handle, axes_handle
</code></pre>
<h2 id="usage-example">Usage example</h2>
<pre><code>&gt;&gt;&gt;import a1das
&gt;&gt;&gt;f=a1das.open(filename)
&gt;&gt;&gt;a1=f.read()
&gt;&gt;&gt;a1.rplot()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rplot(self, fig=None, cmap=&#39;RdBu&#39;, vrange=None, splot=(1, 1, 1), title=&#39;&#39;, drange=None, trange=None):
    &#34;&#34;&#34;
    ##Description
    Produce a raster plot of the das section
    ##Input
        fig= figure handle (default None)
        cmap= colormap (default=RdBu)
        vrange= trace amplitude range (default None)
        splot= plot as a subplot (default subplot(1,1,1))
        title= figure title (default None)
        drange= distance range
        trange= time range

    ## Return
        figure_handle, axes_handle

    ##Usage example
        &gt;&gt;&gt;import a1das
        &gt;&gt;&gt;f=a1das.open(filename)
        &gt;&gt;&gt;a1=f.read()
        &gt;&gt;&gt;a1.rplot()
    &#34;&#34;&#34;
    from a1das._plot import rplot
    from ._a1das_exception import ReadDataError

    if self.data is None:
        raise ReadDataError(&#39;Hum Hum, read data before plotting ...&#39;)

    fig, ax = rplot(self,fig, cmap, vrange, splot, title, drange, trange)

    return fig, ax</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>a.save(filename)</p>
<p>Save a <code><a title="a1das.core.A1Section" href="#a1das.core.A1Section">A1Section</a></code> that has been read, extracted or converted from stream or files into the reducted file format.</p>
<h2 id="input">Input</h2>
<p>filename= a name for the hdf5 file that contains the reducted file</p>
<h2 id="usage-example">Usage example</h2>
<pre><code>&gt;&gt;&gt; import a1das
&gt;&gt;&gt; f = a1das.open('my_filename', format='febus')
&gt;&gt;&gt; a = f.read(trange=(tmin,tmax), drange=(dmin,dmax), skip=False) # read and extract a subportion of the original file
&gt;&gt;&gt; a.save('new_section') # 'a' can be read later using the same a1das.open() and f.read() functions
&gt;&gt;&gt; f.close()
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self,filename):
    &#34;&#34;&#34;
    ## Description
    a.save(filename)

    Save a `A1Section` that has been read, extracted or converted from stream or files into the reducted file format.

    ## Input
    filename= a name for the hdf5 file that contains the reducted file

    ## Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f = a1das.open(&#39;my_filename&#39;, format=&#39;febus&#39;)
        &gt;&gt;&gt; a = f.read(trange=(tmin,tmax), drange=(dmin,dmax), skip=False) # read and extract a subportion of the original file
        &gt;&gt;&gt; a.save(&#39;new_section&#39;) # &#39;a&#39; can be read later using the same a1das.open() and f.read() functions
        &gt;&gt;&gt; f.close()

    &#34;&#34;&#34;
    from ._core_reducted_file import _save_reducted_file
    _save_reducted_file(self,filename)</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.set_item"><code class="name flex">
<span>def <span class="ident">set_item</span></span>(<span>self, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Update/create a matadata entry in the data_header class dictionnary attached to A1Section</p>
<h2 id="input">Input</h2>
<pre><code>**kwargs = arbitrary list of key_word = value
</code></pre>
<h2 id="usage-example">Usage example</h2>
<pre><code>&gt;&gt;&gt; import a1das
&gt;&gt;&gt; f=a1das.open(filename)
&gt;&gt;&gt; a=f.read()
&gt;&gt;&gt; a.set_item(cat_name='medor',cat_food='candies',cat_age=7)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_item(self, **kwargs):
    &#34;&#34;&#34;
    ##Description
    Update/create a matadata entry in the data_header class dictionnary attached to A1Section

    ##Input
        **kwargs = arbitrary list of key_word = value
    ##Usage example
        &gt;&gt;&gt; import a1das
        &gt;&gt;&gt; f=a1das.open(filename)
        &gt;&gt;&gt; a=f.read()
        &gt;&gt;&gt; a.set_item(cat_name=&#39;medor&#39;,cat_food=&#39;candies&#39;,cat_age=7)

    &#34;&#34;&#34;
    self.data_header.set_item(kwargs)</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.set_otime_from_filename"><code class="name flex">
<span>def <span class="ident">set_otime_from_filename</span></span>(<span>self, offset=0.0, prefix=None)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Set data header origin time from the filename assuming Febus convention on the filename
ex: SR_2021-08-26_14-32-39_UTC.h5.
This call affect the origin time to file header and is propagated to all subsequent A1File.read() call
This does not affect the values of the <time> vector which always refer to the origin (ie starting) time</p>
<h2 id="input">Input</h2>
<pre><code>offset = a time offset to add/substract from the filename information
prefix = a prefix ending by "_" in case the filename do not follow Febus convention (SR_, RAW_, S_, ...)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_otime_from_filename(self, offset=0., prefix=None):
    &#34;&#34;&#34;
    ##Description
    Set data header origin time from the filename assuming Febus convention on the filename
    ex: SR_2021-08-26_14-32-39_UTC.h5.
    This call affect the origin time to file header and is propagated to all subsequent A1File.read() call
    This does not affect the values of the &lt;time&gt; vector which always refer to the origin (ie starting) time

    ##Input
        offset = a time offset to add/substract from the filename information
        prefix = a prefix ending by &#34;_&#34; in case the filename do not follow Febus convention (SR_, RAW_, S_, ...)
    &#34;&#34;&#34;
    from datetime import timezone, datetime
    from ._a1das_exception import WrongValueError

    if &#39;filename&#39; in self.data_header._header.keys():
        name = self.data_header[&#39;filename&#39;]
        # expected to be of the form SR_2021-08-26_14-32-39_UTC.h5
        if prefix is None:
            start = name.find(&#34;_&#34;)
            ofs = 1
        else:
            start = name.find(prefix)
            ofs = len(prefix)

        if start == -1:
            raise WrongValueError(&#39;could not set origin time from filename, check filename and/or prefix&#39;)
            return
        end = name.find(&#34;_UTC&#34;)
        s = name[start+ofs:end]
        # convert from string
        try:
            d = datetime.strptime(s, &#34;%Y-%m-%d_%H-%M-%S&#34;)
        except:
            raise ValueError(&#39;wrong date-time format, check file prefix&#39;)

        # convert to UTC
        dd = datetime(d.year,d.month,d.day,d.hour,d.minute,d.second, tzinfo=timezone.utc)
        # convert to Posix
        self.data_header.set_item(otime=dd.timestamp()+offset)
    else:
        raise WrongValueError(&#39;&lt;filename&gt; is not defined in data header&#39;)</code></pre>
</details>
</dd>
<dt id="a1das.core.A1Section.time"><code class="name flex">
<span>def <span class="ident">time</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="description">Description</h2>
<p>Return the time vector defined in the <A1Section> data_header, i.e. shortcut for a1.data_header['time']</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def time(self):
    &#34;&#34;&#34;
    ## Description
    Return the time vector defined in the &lt;A1Section&gt; data_header, i.e. shortcut for a1.data_header[&#39;time&#39;]
    &#34;&#34;&#34;
    return self.data_header[&#39;time&#39;]</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="a1das" href="index.html">a1das</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="a1das.core.open" href="#a1das.core.open">open</a></code></li>
<li><code><a title="a1das.core.tcp_address" href="#a1das.core.tcp_address">tcp_address</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="a1das.core.A1File" href="#a1das.core.A1File">A1File</a></code></h4>
<ul class="">
<li><code><a title="a1das.core.A1File.close" href="#a1das.core.A1File.close">close</a></code></li>
<li><code><a title="a1das.core.A1File.dist" href="#a1das.core.A1File.dist">dist</a></code></li>
<li><code><a title="a1das.core.A1File.read" href="#a1das.core.A1File.read">read</a></code></li>
<li><code><a title="a1das.core.A1File.set_item" href="#a1das.core.A1File.set_item">set_item</a></code></li>
<li><code><a title="a1das.core.A1File.set_otime_from_filename" href="#a1das.core.A1File.set_otime_from_filename">set_otime_from_filename</a></code></li>
<li><code><a title="a1das.core.A1File.time" href="#a1das.core.A1File.time">time</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="a1das.core.A1Section" href="#a1das.core.A1Section">A1Section</a></code></h4>
<ul class="">
<li><code><a title="a1das.core.A1Section.concat" href="#a1das.core.A1Section.concat">concat</a></code></li>
<li><code><a title="a1das.core.A1Section.dist" href="#a1das.core.A1Section.dist">dist</a></code></li>
<li><code><a title="a1das.core.A1Section.index" href="#a1das.core.A1Section.index">index</a></code></li>
<li><code><a title="a1das.core.A1Section.obspy_stream" href="#a1das.core.A1Section.obspy_stream">obspy_stream</a></code></li>
<li><code><a title="a1das.core.A1Section.otime" href="#a1das.core.A1Section.otime">otime</a></code></li>
<li><code><a title="a1das.core.A1Section.plot" href="#a1das.core.A1Section.plot">plot</a></code></li>
<li><code><a title="a1das.core.A1Section.rplot" href="#a1das.core.A1Section.rplot">rplot</a></code></li>
<li><code><a title="a1das.core.A1Section.save" href="#a1das.core.A1Section.save">save</a></code></li>
<li><code><a title="a1das.core.A1Section.set_item" href="#a1das.core.A1Section.set_item">set_item</a></code></li>
<li><code><a title="a1das.core.A1Section.set_otime_from_filename" href="#a1das.core.A1Section.set_otime_from_filename">set_otime_from_filename</a></code></li>
<li><code><a title="a1das.core.A1Section.time" href="#a1das.core.A1Section.time">time</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>